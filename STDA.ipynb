{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/opt/conda/lib/python3.6/site-packages/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZN3c104impl25tls_local_tensor_type_setEv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d96cc79c1947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectron_pro\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmask_img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/final/pedestrian_generator/datasets/detectron_pro.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# import some common detectron2 utilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_zoo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDefaultPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/detectron2/model_zoo/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m`\u001b[0m\u001b[0mMODEL_ZOO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmd\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mgithub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfacebookresearch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdetectron2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mMODEL_ZOO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \"\"\"\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel_zoo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_checkpoint_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"get_checkpoint_url\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_config_file\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/detectron2/model_zoo/model_zoo.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetectionCheckpointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/detectron2/modeling/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShapeSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0manchor_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_anchor_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mANCHOR_GENERATOR_REGISTRY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/detectron2/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch_norm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFrozenBatchNorm2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNaiveSyncBatchNorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeform_conv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeformConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModulatedDeformConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmask_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaste_masks_in_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatched_nms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched_nms_rotated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms_rotated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/detectron2/layers/deform_conv.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_NewEmptyTensorOp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /opt/conda/lib/python3.6/site-packages/detectron2/_C.cpython-36m-x86_64-linux-gnu.so: undefined symbol: _ZN3c104impl25tls_local_tensor_type_setEv"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from models import CompletionNetwork, ContextDiscriminator, GlobalDiscriminator_P\n",
    "from datasets2 import ImageDataset\n",
    "from losses import completion_network_loss, completion_network_loss_P\n",
    "from noise import AddGaussianNoise\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adadelta, Adam\n",
    "from torch.nn import BCELoss, DataParallel\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from datasets.detectron_pro import mask_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=1000\n",
    "\n",
    "snaperiod=50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"/root/notebooks/final/gandata/gandata1\"\n",
    "result_dir=\"/root/notebooks/final/gandata/result\"\n",
    "\n",
    "\n",
    "gpu = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset... (it may take a few minutes)\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "\n",
    "trnsfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n",
    "\n",
    "trnsfm2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    AddGaussianNoise(0., 0.001)\n",
    "])\n",
    "print('loading dataset... (it may take a few minutes)')\n",
    "train_dset = ImageDataset(data_dir, trnsfm,trnsfm2, load2meme = False)\n",
    "test_dset = ImageDataset(data_dir, trnsfm,trnsfm2, load2meme = False)\n",
    "train_loader = DataLoader(train_dset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model G\n",
    "\n",
    "model_G = CompletionNetwork()\n",
    "model_G = DataParallel(model_G)\n",
    "opt_G = Adam(model_G.parameters())\n",
    "model_G = model_G.to(gpu)\n",
    "\n",
    "# Create model D\n",
    "model_D = GlobalDiscriminator_P((3,256,256))\n",
    "model_D = DataParallel(model_D)\n",
    "opt_D = Adam(model_D.parameters())\n",
    "model_D = model_D.to(gpu)\n",
    "\n",
    "bceloss = BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion_loss(background, person, output, lefttop, height = 64 , width = 32, devices = 'cuda:0'):\n",
    "    \"\"\"\n",
    "    * background:\n",
    "        - shape: batchsize * 3 * 256 * 256\n",
    "    * output:\n",
    "        - shape: batchsize * 3 * 256 * 256\n",
    "    \"\"\"\n",
    "    output_crop = torch.zeros([output.shape[0],3,128,64]).to(devices)\n",
    "    person_crop = torch.zeros([output.shape[0],3,128,64]).to(devices)\n",
    "    \n",
    "    #mask = torch.zeros(size = output.shape).to(devices)\n",
    "    batchsize = output.shape[0]\n",
    "    for i in range(batchsize):\n",
    "        left , top = lefttop[i][0],lefttop[i][1]\n",
    "        output_crop[i,:,:,:] = output[i,:,top : top + height , left : left + width]\n",
    "        person_crop[i,:,:,:] = person[i,:,top : top + height , left : left + width]\n",
    "        #mask[ i ,:, top : top + height , left : left + width]  = 1\n",
    "\n",
    "    return 0.7*mse_loss(output_crop, person_crop) + 0.3*mse_loss(output, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_G(n,steps):\n",
    "    cnt_bdivs = 0\n",
    "    pbar = tqdm(total=steps)\n",
    "    while pbar.n < steps:\n",
    "        for street_img, mask_with_poeple, left_top in train_loader:\n",
    "            street_img = street_img.to(gpu)\n",
    "            mask_with_poeple = mask_with_poeple.to(gpu)\n",
    "\n",
    "            input = torch.cat((street_img, mask_with_poeple), dim=1)\n",
    "            output = model_G(input)\n",
    "            #loss = completion_network_loss(x, output, mask)\n",
    "            #loss = torch.nn.functional.mse_loss(output, street_img)\n",
    "            \n",
    "            loss = completion_loss(street_img, mask_with_poeple, output, left_top, height = 128 , width = 64)\n",
    "\n",
    "            # backward\n",
    "            loss.backward()\n",
    "            cnt_bdivs += 1\n",
    "\n",
    "            # optimize\n",
    "            opt_cn.step()\n",
    "            # clear grads\n",
    "            opt_cn.zero_grad()\n",
    "            # update progbar\n",
    "            pbar.set_description('%d | phase 1 | train loss: %.5f' % (n,loss.cpu()))\n",
    "            pbar.update()\n",
    "            if pbar.n % snaperiod == 0:\n",
    "                with torch.no_grad():\n",
    "                    x1, x2 = sample_random_batch(test_dset, batch_size=3)\n",
    "                    x1 = x1.to(gpu)\n",
    "                    x2 = x2.to(gpu)\n",
    "\n",
    "                    input = torch.cat((x1, x2), dim=1)\n",
    "                    output = model_G(input)\n",
    "                    completed = poisson_blend(x1, output, x2)\n",
    "                    imgs = torch.cat((x1.cpu(), x2.cpu(), output.cpu(),completed.cpu()), dim=2)\n",
    "                    imgpath = os.path.join(result_dir, 'phase_1', '%d_step%d.png' % (n , pbar.n))\n",
    "                    model_G_path = os.path.join(result_dir, 'phase_1', '%d_model_cn_step%d' % (n , pbar.n))\n",
    "                    save_image(imgs, imgpath, nrow=len(x1))\n",
    "                    torch.save(model_G.state_dict(), model_G_path)\n",
    "            # terminate\n",
    "            if pbar.n >= steps:\n",
    "                break\n",
    "                \n",
    "    pbar.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
