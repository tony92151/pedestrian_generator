{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to restart your runtime prior to this, to let your installation take effect\n",
    "# Some basic setup\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "#from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from detectron2.structures import BoxMode\n",
    "def cv2_imshow(img):\n",
    "    img = img[:,:,[2,1,0]]\n",
    "    img = Image.fromarray(img)\n",
    "    display(img)\n",
    "    '''plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    #img = transforms.ToPILImage(img)\n",
    "    #plt.show(img)\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46024 46024\n",
      "['/root/notebooks/Module_final/caltech_origin_data_refine/street/045034.jpg', '/root/notebooks/Module_final/caltech_origin_data_refine/street/031156.jpg']\n",
      "['/root/notebooks/Module_final/caltech_origin_data_refine/street_json/045034.json', '/root/notebooks/Module_final/caltech_origin_data_refine/street_json/031156.json']\n"
     ]
    }
   ],
   "source": [
    "people_jsonlist = []\n",
    "people_imagelist = []\n",
    "with open('/root/notebooks/Module_final/pedestrian_generator/Detectron2/people_jsonlist_final_v2', 'r') as j:\n",
    "    lines = j.readlines()\n",
    "    for line in lines:\n",
    "        people_jsonlist.append(line[:-1])\n",
    "with open('/root/notebooks/Module_final/pedestrian_generator/Detectron2/people_imagelist_final_v2', 'r') as i:\n",
    "    lines = i.readlines()\n",
    "    for line in lines:\n",
    "        people_imagelist.append(line[:-1])\n",
    "\n",
    "print(len(people_jsonlist), len(people_imagelist))\n",
    "print(people_imagelist[:2])\n",
    "print(people_jsonlist[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000\n",
      "42000\n",
      "4024\n",
      "4024\n",
      "/root/notebooks/Module_final/caltech_origin_data_refine/street_json/096474.json\n"
     ]
    }
   ],
   "source": [
    "train_people_jsonlist = people_jsonlist[:-4024]\n",
    "train_people_imagelist = people_imagelist[:-4024]\n",
    "test_people_jsonlist = people_jsonlist[-4024:]\n",
    "test_people_imagelist = people_imagelist[-4024:]\n",
    "print(len(train_people_imagelist))\n",
    "print(len(train_people_jsonlist))\n",
    "\n",
    "print(len(test_people_imagelist))\n",
    "print(len(test_people_jsonlist))\n",
    "\n",
    "print(test_people_jsonlist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pedestrain_dict(image_list, json_list):\n",
    "    dataset_dicts = []\n",
    "    \n",
    "    for i,path in tqdm(enumerate(image_list)):\n",
    "        filename = path\n",
    "        #img = cv2.imread(path)\n",
    "        # height, width = cv2.imread(filename).shape[:2]\n",
    "        record = {}\n",
    "        record['file_name'] = filename\n",
    "        record['image_id'] = i #path.split('/')[-1][:-5]\n",
    "        #id is like 000000 or 000001\n",
    "        #record['file_img'] = img\n",
    "        record['height']= 480\n",
    "        record['width']= 640\n",
    "        \n",
    "        #for i in data_list[1] to get bbox and category\n",
    "        objs = []\n",
    "        \n",
    "        people = json_list[i]\n",
    "        with open(people) as p:\n",
    "            json_context = json.load(p)\n",
    "            for person in json_context:\n",
    "                boxes = list(map(float, person['pos']))\n",
    "                obj = {\n",
    "                    \"bbox\": boxes,\n",
    "                    \"bbox_mode\": BoxMode.XYWH_ABS,\n",
    "                    #\"segmentation\": [poly], To draw a line, along to ballon\n",
    "                    \"category_id\": 0,\n",
    "                    \"iscrowd\": 0\n",
    "                }\n",
    "                objs.append(obj)\n",
    "            record[\"annotations\"] = objs\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts #list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metadata(name='pedestrain_test', thing_classes=['person'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "DatasetCatalog.register(\"pedestrain_test\", lambda i=i: get_pedestrain_dict(test_people_imagelist, test_people_jsonlist))\n",
    "MetadataCatalog.get(\"pedestrain_test\").set(thing_classes=[\"person\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"Base-RCNN-FPN.yaml\"))\n",
    "#cfg.DATASETS.TRAIN = (\"pedestrain_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "#cfg.MODEL.WEIGHTS = \"detectron2://ImageNetPretrained/MSRA/R-50.pkl\"#model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_1x.yaml\")\n",
    "#cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 3\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER =  156000   # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1 \n",
    "cfg.OUTPUT_DIR = '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0004999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0009999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0014999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0019999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0024999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0029999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0034999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0039999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0044999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0049999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0054999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0059999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0064999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0069999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0074999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0079999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0084999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0089999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0094999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0099999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0104999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0109999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0114999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0119999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0124999.pth', '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_final.pth']\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "model_list = sorted(glob.glob('/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model*'))\n",
    "print(model_list)\n",
    "print(len(model_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0004999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0009999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0014999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0019999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0024999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0029999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0034999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0039999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0044999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0049999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0054999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0059999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0064999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0069999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0074999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0079999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0084999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0089999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0094999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0099999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0104999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0109999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0114999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0119999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_0124999.pth',\n",
       " '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_final.pth']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4024it [00:06, 647.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/26 23:16:01 d2.data.common]: \u001b[0mSerializing 4024 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/26 23:16:01 d2.data.common]: \u001b[0mSerialized dataset takes 1.47 MiB\n",
      "\u001b[32m[06/26 23:16:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 4024 images\n",
      "\u001b[32m[06/26 23:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/4024. 0.0395 s / img. ETA=0:02:42\n",
      "\u001b[32m[06/26 23:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 134/4024. 0.0393 s / img. ETA=0:02:38\n",
      "\u001b[32m[06/26 23:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 258/4024. 0.0392 s / img. ETA=0:02:32\n",
      "\u001b[32m[06/26 23:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 382/4024. 0.0392 s / img. ETA=0:02:27\n",
      "\u001b[32m[06/26 23:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 507/4024. 0.0391 s / img. ETA=0:02:22\n",
      "\u001b[32m[06/26 23:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 632/4024. 0.0391 s / img. ETA=0:02:17\n",
      "\u001b[32m[06/26 23:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 756/4024. 0.0390 s / img. ETA=0:02:11\n",
      "\u001b[32m[06/26 23:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 880/4024. 0.0391 s / img. ETA=0:02:07\n",
      "\u001b[32m[06/26 23:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 1003/4024. 0.0391 s / img. ETA=0:02:02\n",
      "\u001b[32m[06/26 23:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 1128/4024. 0.0391 s / img. ETA=0:01:57\n",
      "\u001b[32m[06/26 23:16:52 d2.evaluation.evaluator]: \u001b[0mInference done 1253/4024. 0.0391 s / img. ETA=0:01:51\n",
      "\u001b[32m[06/26 23:16:57 d2.evaluation.evaluator]: \u001b[0mInference done 1378/4024. 0.0390 s / img. ETA=0:01:46\n",
      "\u001b[32m[06/26 23:17:02 d2.evaluation.evaluator]: \u001b[0mInference done 1503/4024. 0.0390 s / img. ETA=0:01:41\n",
      "\u001b[32m[06/26 23:17:07 d2.evaluation.evaluator]: \u001b[0mInference done 1627/4024. 0.0390 s / img. ETA=0:01:36\n",
      "\u001b[32m[06/26 23:17:12 d2.evaluation.evaluator]: \u001b[0mInference done 1750/4024. 0.0391 s / img. ETA=0:01:31\n",
      "\u001b[32m[06/26 23:17:17 d2.evaluation.evaluator]: \u001b[0mInference done 1874/4024. 0.0391 s / img. ETA=0:01:26\n",
      "\u001b[32m[06/26 23:17:22 d2.evaluation.evaluator]: \u001b[0mInference done 1998/4024. 0.0391 s / img. ETA=0:01:21\n",
      "\u001b[32m[06/26 23:17:27 d2.evaluation.evaluator]: \u001b[0mInference done 2122/4024. 0.0391 s / img. ETA=0:01:16\n",
      "\u001b[32m[06/26 23:17:32 d2.evaluation.evaluator]: \u001b[0mInference done 2247/4024. 0.0391 s / img. ETA=0:01:11\n",
      "\u001b[32m[06/26 23:17:37 d2.evaluation.evaluator]: \u001b[0mInference done 2371/4024. 0.0391 s / img. ETA=0:01:06\n",
      "\u001b[32m[06/26 23:17:42 d2.evaluation.evaluator]: \u001b[0mInference done 2495/4024. 0.0391 s / img. ETA=0:01:01\n",
      "\u001b[32m[06/26 23:17:47 d2.evaluation.evaluator]: \u001b[0mInference done 2620/4024. 0.0391 s / img. ETA=0:00:56\n",
      "\u001b[32m[06/26 23:17:52 d2.evaluation.evaluator]: \u001b[0mInference done 2743/4024. 0.0391 s / img. ETA=0:00:51\n",
      "\u001b[32m[06/26 23:17:57 d2.evaluation.evaluator]: \u001b[0mInference done 2868/4024. 0.0391 s / img. ETA=0:00:46\n",
      "\u001b[32m[06/26 23:18:02 d2.evaluation.evaluator]: \u001b[0mInference done 2993/4024. 0.0391 s / img. ETA=0:00:41\n",
      "\u001b[32m[06/26 23:18:07 d2.evaluation.evaluator]: \u001b[0mInference done 3117/4024. 0.0391 s / img. ETA=0:00:36\n",
      "\u001b[32m[06/26 23:18:12 d2.evaluation.evaluator]: \u001b[0mInference done 3241/4024. 0.0391 s / img. ETA=0:00:31\n",
      "\u001b[32m[06/26 23:18:17 d2.evaluation.evaluator]: \u001b[0mInference done 3365/4024. 0.0391 s / img. ETA=0:00:26\n",
      "\u001b[32m[06/26 23:18:22 d2.evaluation.evaluator]: \u001b[0mInference done 3490/4024. 0.0391 s / img. ETA=0:00:21\n",
      "\u001b[32m[06/26 23:18:27 d2.evaluation.evaluator]: \u001b[0mInference done 3615/4024. 0.0391 s / img. ETA=0:00:16\n",
      "\u001b[32m[06/26 23:18:32 d2.evaluation.evaluator]: \u001b[0mInference done 3740/4024. 0.0391 s / img. ETA=0:00:11\n",
      "\u001b[32m[06/26 23:18:37 d2.evaluation.evaluator]: \u001b[0mInference done 3864/4024. 0.0391 s / img. ETA=0:00:06\n",
      "\u001b[32m[06/26 23:18:42 d2.evaluation.evaluator]: \u001b[0mInference done 3988/4024. 0.0391 s / img. ETA=0:00:01\n",
      "\u001b[32m[06/26 23:18:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:42.370213 (0.040401 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:18:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:37 (0.039091 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:18:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/26 23:18:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/coco_instances_results.json\n",
      "\u001b[32m[06/26 23:18:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/26 23:18:44 d2.evaluation.coco_evaluation]: \u001b[0mNo predictions from the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4024it [00:06, 646.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/26 23:18:54 d2.data.common]: \u001b[0mSerializing 4024 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/26 23:18:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.47 MiB\n",
      "\u001b[32m[06/26 23:18:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 4024 images\n",
      "\u001b[32m[06/26 23:18:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/4024. 0.0390 s / img. ETA=0:02:40\n",
      "\u001b[32m[06/26 23:19:00 d2.evaluation.evaluator]: \u001b[0mInference done 136/4024. 0.0389 s / img. ETA=0:02:36\n",
      "\u001b[32m[06/26 23:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 261/4024. 0.0389 s / img. ETA=0:02:31\n",
      "\u001b[32m[06/26 23:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 385/4024. 0.0390 s / img. ETA=0:02:26\n",
      "\u001b[32m[06/26 23:19:15 d2.evaluation.evaluator]: \u001b[0mInference done 509/4024. 0.0390 s / img. ETA=0:02:21\n",
      "\u001b[32m[06/26 23:19:20 d2.evaluation.evaluator]: \u001b[0mInference done 632/4024. 0.0391 s / img. ETA=0:02:16\n",
      "\u001b[32m[06/26 23:19:25 d2.evaluation.evaluator]: \u001b[0mInference done 757/4024. 0.0390 s / img. ETA=0:02:11\n",
      "\u001b[32m[06/26 23:19:30 d2.evaluation.evaluator]: \u001b[0mInference done 880/4024. 0.0391 s / img. ETA=0:02:07\n",
      "\u001b[32m[06/26 23:19:35 d2.evaluation.evaluator]: \u001b[0mInference done 1004/4024. 0.0391 s / img. ETA=0:02:02\n",
      "\u001b[32m[06/26 23:19:40 d2.evaluation.evaluator]: \u001b[0mInference done 1128/4024. 0.0391 s / img. ETA=0:01:57\n",
      "\u001b[32m[06/26 23:19:45 d2.evaluation.evaluator]: \u001b[0mInference done 1252/4024. 0.0391 s / img. ETA=0:01:52\n",
      "\u001b[32m[06/26 23:19:50 d2.evaluation.evaluator]: \u001b[0mInference done 1376/4024. 0.0391 s / img. ETA=0:01:47\n",
      "\u001b[32m[06/26 23:19:55 d2.evaluation.evaluator]: \u001b[0mInference done 1501/4024. 0.0391 s / img. ETA=0:01:41\n",
      "\u001b[32m[06/26 23:20:00 d2.evaluation.evaluator]: \u001b[0mInference done 1626/4024. 0.0391 s / img. ETA=0:01:36\n",
      "\u001b[32m[06/26 23:20:05 d2.evaluation.evaluator]: \u001b[0mInference done 1751/4024. 0.0391 s / img. ETA=0:01:31\n",
      "\u001b[32m[06/26 23:20:10 d2.evaluation.evaluator]: \u001b[0mInference done 1875/4024. 0.0391 s / img. ETA=0:01:26\n",
      "\u001b[32m[06/26 23:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 1999/4024. 0.0391 s / img. ETA=0:01:21\n",
      "\u001b[32m[06/26 23:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 2123/4024. 0.0391 s / img. ETA=0:01:16\n",
      "\u001b[32m[06/26 23:20:25 d2.evaluation.evaluator]: \u001b[0mInference done 2248/4024. 0.0391 s / img. ETA=0:01:11\n",
      "\u001b[32m[06/26 23:20:30 d2.evaluation.evaluator]: \u001b[0mInference done 2373/4024. 0.0391 s / img. ETA=0:01:06\n",
      "\u001b[32m[06/26 23:20:35 d2.evaluation.evaluator]: \u001b[0mInference done 2498/4024. 0.0390 s / img. ETA=0:01:01\n",
      "\u001b[32m[06/26 23:20:40 d2.evaluation.evaluator]: \u001b[0mInference done 2622/4024. 0.0390 s / img. ETA=0:00:56\n",
      "\u001b[32m[06/26 23:20:45 d2.evaluation.evaluator]: \u001b[0mInference done 2746/4024. 0.0390 s / img. ETA=0:00:51\n",
      "\u001b[32m[06/26 23:20:50 d2.evaluation.evaluator]: \u001b[0mInference done 2871/4024. 0.0390 s / img. ETA=0:00:46\n",
      "\u001b[32m[06/26 23:20:55 d2.evaluation.evaluator]: \u001b[0mInference done 2995/4024. 0.0391 s / img. ETA=0:00:41\n",
      "\u001b[32m[06/26 23:21:00 d2.evaluation.evaluator]: \u001b[0mInference done 3121/4024. 0.0390 s / img. ETA=0:00:36\n",
      "\u001b[32m[06/26 23:21:05 d2.evaluation.evaluator]: \u001b[0mInference done 3246/4024. 0.0390 s / img. ETA=0:00:31\n",
      "\u001b[32m[06/26 23:21:10 d2.evaluation.evaluator]: \u001b[0mInference done 3371/4024. 0.0390 s / img. ETA=0:00:26\n",
      "\u001b[32m[06/26 23:21:16 d2.evaluation.evaluator]: \u001b[0mInference done 3495/4024. 0.0390 s / img. ETA=0:00:21\n",
      "\u001b[32m[06/26 23:21:21 d2.evaluation.evaluator]: \u001b[0mInference done 3620/4024. 0.0390 s / img. ETA=0:00:16\n",
      "\u001b[32m[06/26 23:21:26 d2.evaluation.evaluator]: \u001b[0mInference done 3744/4024. 0.0390 s / img. ETA=0:00:11\n",
      "\u001b[32m[06/26 23:21:31 d2.evaluation.evaluator]: \u001b[0mInference done 3869/4024. 0.0390 s / img. ETA=0:00:06\n",
      "\u001b[32m[06/26 23:21:36 d2.evaluation.evaluator]: \u001b[0mInference done 3994/4024. 0.0390 s / img. ETA=0:00:01\n",
      "\u001b[32m[06/26 23:21:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:42.177919 (0.040353 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:21:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:36 (0.039041 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:21:37 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/26 23:21:37 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/coco_instances_results.json\n",
      "\u001b[32m[06/26 23:21:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.79s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.13s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "\u001b[32m[06/26 23:21:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.792 | 0.990  | 0.990  | 0.792 | 0.347 | 0.000 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4024it [00:07, 543.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/26 23:21:50 d2.data.common]: \u001b[0mSerializing 4024 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/26 23:21:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.47 MiB\n",
      "\u001b[32m[06/26 23:21:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 4024 images\n",
      "\u001b[32m[06/26 23:21:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/4024. 0.0390 s / img. ETA=0:02:40\n",
      "\u001b[32m[06/26 23:21:56 d2.evaluation.evaluator]: \u001b[0mInference done 135/4024. 0.0392 s / img. ETA=0:02:37\n",
      "\u001b[32m[06/26 23:22:01 d2.evaluation.evaluator]: \u001b[0mInference done 260/4024. 0.0391 s / img. ETA=0:02:32\n",
      "\u001b[32m[06/26 23:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 385/4024. 0.0390 s / img. ETA=0:02:26\n",
      "\u001b[32m[06/26 23:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 509/4024. 0.0390 s / img. ETA=0:02:21\n",
      "\u001b[32m[06/26 23:22:16 d2.evaluation.evaluator]: \u001b[0mInference done 633/4024. 0.0391 s / img. ETA=0:02:16\n",
      "\u001b[32m[06/26 23:22:21 d2.evaluation.evaluator]: \u001b[0mInference done 756/4024. 0.0391 s / img. ETA=0:02:12\n",
      "\u001b[32m[06/26 23:22:26 d2.evaluation.evaluator]: \u001b[0mInference done 879/4024. 0.0392 s / img. ETA=0:02:07\n",
      "\u001b[32m[06/26 23:22:31 d2.evaluation.evaluator]: \u001b[0mInference done 1003/4024. 0.0392 s / img. ETA=0:02:02\n",
      "\u001b[32m[06/26 23:22:36 d2.evaluation.evaluator]: \u001b[0mInference done 1124/4024. 0.0393 s / img. ETA=0:01:57\n",
      "\u001b[32m[06/26 23:22:41 d2.evaluation.evaluator]: \u001b[0mInference done 1248/4024. 0.0392 s / img. ETA=0:01:52\n",
      "\u001b[32m[06/26 23:22:46 d2.evaluation.evaluator]: \u001b[0mInference done 1371/4024. 0.0393 s / img. ETA=0:01:47\n",
      "\u001b[32m[06/26 23:22:51 d2.evaluation.evaluator]: \u001b[0mInference done 1492/4024. 0.0393 s / img. ETA=0:01:42\n",
      "\u001b[32m[06/26 23:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 1616/4024. 0.0393 s / img. ETA=0:01:37\n",
      "\u001b[32m[06/26 23:23:01 d2.evaluation.evaluator]: \u001b[0mInference done 1741/4024. 0.0393 s / img. ETA=0:01:32\n",
      "\u001b[32m[06/26 23:23:06 d2.evaluation.evaluator]: \u001b[0mInference done 1865/4024. 0.0393 s / img. ETA=0:01:27\n",
      "\u001b[32m[06/26 23:23:11 d2.evaluation.evaluator]: \u001b[0mInference done 1989/4024. 0.0393 s / img. ETA=0:01:22\n",
      "\u001b[32m[06/26 23:23:16 d2.evaluation.evaluator]: \u001b[0mInference done 2112/4024. 0.0393 s / img. ETA=0:01:17\n",
      "\u001b[32m[06/26 23:23:21 d2.evaluation.evaluator]: \u001b[0mInference done 2236/4024. 0.0393 s / img. ETA=0:01:12\n",
      "\u001b[32m[06/26 23:23:26 d2.evaluation.evaluator]: \u001b[0mInference done 2359/4024. 0.0393 s / img. ETA=0:01:07\n",
      "\u001b[32m[06/26 23:23:31 d2.evaluation.evaluator]: \u001b[0mInference done 2484/4024. 0.0393 s / img. ETA=0:01:02\n",
      "\u001b[32m[06/26 23:23:36 d2.evaluation.evaluator]: \u001b[0mInference done 2609/4024. 0.0393 s / img. ETA=0:00:57\n",
      "\u001b[32m[06/26 23:23:41 d2.evaluation.evaluator]: \u001b[0mInference done 2733/4024. 0.0393 s / img. ETA=0:00:52\n",
      "\u001b[32m[06/26 23:23:46 d2.evaluation.evaluator]: \u001b[0mInference done 2857/4024. 0.0393 s / img. ETA=0:00:47\n",
      "\u001b[32m[06/26 23:23:51 d2.evaluation.evaluator]: \u001b[0mInference done 2981/4024. 0.0393 s / img. ETA=0:00:42\n",
      "\u001b[32m[06/26 23:23:56 d2.evaluation.evaluator]: \u001b[0mInference done 3105/4024. 0.0393 s / img. ETA=0:00:37\n",
      "\u001b[32m[06/26 23:24:01 d2.evaluation.evaluator]: \u001b[0mInference done 3229/4024. 0.0393 s / img. ETA=0:00:32\n",
      "\u001b[32m[06/26 23:24:06 d2.evaluation.evaluator]: \u001b[0mInference done 3354/4024. 0.0393 s / img. ETA=0:00:27\n",
      "\u001b[32m[06/26 23:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 3478/4024. 0.0392 s / img. ETA=0:00:22\n",
      "\u001b[32m[06/26 23:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 3602/4024. 0.0392 s / img. ETA=0:00:17\n",
      "\u001b[32m[06/26 23:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 3726/4024. 0.0392 s / img. ETA=0:00:12\n",
      "\u001b[32m[06/26 23:24:26 d2.evaluation.evaluator]: \u001b[0mInference done 3850/4024. 0.0392 s / img. ETA=0:00:07\n",
      "\u001b[32m[06/26 23:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 3974/4024. 0.0392 s / img. ETA=0:00:02\n",
      "\u001b[32m[06/26 23:24:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:42.988237 (0.040554 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:24:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:37 (0.039228 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:24:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/26 23:24:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/coco_instances_results.json\n",
      "\u001b[32m[06/26 23:24:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.84s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.13s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      "\u001b[32m[06/26 23:24:34 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.878 | 1.673  | 0.990  | 0.822 | 0.551 | 1.763 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4024it [00:06, 633.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/26 23:24:45 d2.data.common]: \u001b[0mSerializing 4024 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/26 23:24:45 d2.data.common]: \u001b[0mSerialized dataset takes 1.47 MiB\n",
      "\u001b[32m[06/26 23:24:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 4024 images\n",
      "\u001b[32m[06/26 23:24:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/4024. 0.0404 s / img. ETA=0:02:46\n",
      "\u001b[32m[06/26 23:24:50 d2.evaluation.evaluator]: \u001b[0mInference done 132/4024. 0.0402 s / img. ETA=0:02:42\n",
      "\u001b[32m[06/26 23:24:55 d2.evaluation.evaluator]: \u001b[0mInference done 255/4024. 0.0398 s / img. ETA=0:02:35\n",
      "\u001b[32m[06/26 23:25:00 d2.evaluation.evaluator]: \u001b[0mInference done 377/4024. 0.0398 s / img. ETA=0:02:30\n",
      "\u001b[32m[06/26 23:25:05 d2.evaluation.evaluator]: \u001b[0mInference done 501/4024. 0.0396 s / img. ETA=0:02:24\n",
      "\u001b[32m[06/26 23:25:10 d2.evaluation.evaluator]: \u001b[0mInference done 625/4024. 0.0395 s / img. ETA=0:02:19\n",
      "\u001b[32m[06/26 23:25:15 d2.evaluation.evaluator]: \u001b[0mInference done 748/4024. 0.0395 s / img. ETA=0:02:13\n",
      "\u001b[32m[06/26 23:25:20 d2.evaluation.evaluator]: \u001b[0mInference done 871/4024. 0.0395 s / img. ETA=0:02:08\n",
      "\u001b[32m[06/26 23:25:26 d2.evaluation.evaluator]: \u001b[0mInference done 994/4024. 0.0395 s / img. ETA=0:02:03\n",
      "\u001b[32m[06/26 23:25:31 d2.evaluation.evaluator]: \u001b[0mInference done 1118/4024. 0.0395 s / img. ETA=0:01:58\n",
      "\u001b[32m[06/26 23:25:36 d2.evaluation.evaluator]: \u001b[0mInference done 1242/4024. 0.0394 s / img. ETA=0:01:53\n",
      "\u001b[32m[06/26 23:25:41 d2.evaluation.evaluator]: \u001b[0mInference done 1366/4024. 0.0394 s / img. ETA=0:01:48\n",
      "\u001b[32m[06/26 23:25:46 d2.evaluation.evaluator]: \u001b[0mInference done 1490/4024. 0.0394 s / img. ETA=0:01:43\n",
      "\u001b[32m[06/26 23:25:51 d2.evaluation.evaluator]: \u001b[0mInference done 1607/4024. 0.0396 s / img. ETA=0:01:39\n",
      "\u001b[32m[06/26 23:25:56 d2.evaluation.evaluator]: \u001b[0mInference done 1657/4024. 0.0415 s / img. ETA=0:01:41\n",
      "\u001b[32m[06/26 23:26:01 d2.evaluation.evaluator]: \u001b[0mInference done 1708/4024. 0.0431 s / img. ETA=0:01:43\n",
      "\u001b[32m[06/26 23:26:06 d2.evaluation.evaluator]: \u001b[0mInference done 1758/4024. 0.0447 s / img. ETA=0:01:44\n",
      "\u001b[32m[06/26 23:26:11 d2.evaluation.evaluator]: \u001b[0mInference done 1808/4024. 0.0462 s / img. ETA=0:01:45\n",
      "\u001b[32m[06/26 23:26:16 d2.evaluation.evaluator]: \u001b[0mInference done 1859/4024. 0.0476 s / img. ETA=0:01:46\n",
      "\u001b[32m[06/26 23:26:21 d2.evaluation.evaluator]: \u001b[0mInference done 1910/4024. 0.0490 s / img. ETA=0:01:46\n",
      "\u001b[32m[06/26 23:26:26 d2.evaluation.evaluator]: \u001b[0mInference done 1962/4024. 0.0502 s / img. ETA=0:01:46\n",
      "\u001b[32m[06/26 23:26:31 d2.evaluation.evaluator]: \u001b[0mInference done 2014/4024. 0.0514 s / img. ETA=0:01:46\n",
      "\u001b[32m[06/26 23:26:36 d2.evaluation.evaluator]: \u001b[0mInference done 2065/4024. 0.0526 s / img. ETA=0:01:45\n",
      "\u001b[32m[06/26 23:26:41 d2.evaluation.evaluator]: \u001b[0mInference done 2117/4024. 0.0536 s / img. ETA=0:01:44\n",
      "\u001b[32m[06/26 23:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 2166/4024. 0.0547 s / img. ETA=0:01:44\n",
      "\u001b[32m[06/26 23:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 2219/4024. 0.0557 s / img. ETA=0:01:42\n",
      "\u001b[32m[06/26 23:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 2270/4024. 0.0566 s / img. ETA=0:01:41\n",
      "\u001b[32m[06/26 23:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 2321/4024. 0.0575 s / img. ETA=0:01:40\n",
      "\u001b[32m[06/26 23:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 2371/4024. 0.0584 s / img. ETA=0:01:38\n",
      "\u001b[32m[06/26 23:27:12 d2.evaluation.evaluator]: \u001b[0mInference done 2422/4024. 0.0592 s / img. ETA=0:01:37\n",
      "\u001b[32m[06/26 23:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 2473/4024. 0.0600 s / img. ETA=0:01:35\n",
      "\u001b[32m[06/26 23:27:22 d2.evaluation.evaluator]: \u001b[0mInference done 2525/4024. 0.0608 s / img. ETA=0:01:33\n",
      "\u001b[32m[06/26 23:27:27 d2.evaluation.evaluator]: \u001b[0mInference done 2577/4024. 0.0614 s / img. ETA=0:01:30\n",
      "\u001b[32m[06/26 23:27:32 d2.evaluation.evaluator]: \u001b[0mInference done 2627/4024. 0.0622 s / img. ETA=0:01:28\n",
      "\u001b[32m[06/26 23:27:37 d2.evaluation.evaluator]: \u001b[0mInference done 2680/4024. 0.0628 s / img. ETA=0:01:26\n",
      "\u001b[32m[06/26 23:27:42 d2.evaluation.evaluator]: \u001b[0mInference done 2732/4024. 0.0634 s / img. ETA=0:01:23\n",
      "\u001b[32m[06/26 23:27:47 d2.evaluation.evaluator]: \u001b[0mInference done 2782/4024. 0.0641 s / img. ETA=0:01:21\n",
      "\u001b[32m[06/26 23:27:52 d2.evaluation.evaluator]: \u001b[0mInference done 2835/4024. 0.0646 s / img. ETA=0:01:18\n",
      "\u001b[32m[06/26 23:27:57 d2.evaluation.evaluator]: \u001b[0mInference done 2888/4024. 0.0652 s / img. ETA=0:01:15\n",
      "\u001b[32m[06/26 23:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 2938/4024. 0.0658 s / img. ETA=0:01:12\n",
      "\u001b[32m[06/26 23:28:07 d2.evaluation.evaluator]: \u001b[0mInference done 2990/4024. 0.0663 s / img. ETA=0:01:09\n",
      "\u001b[32m[06/26 23:28:12 d2.evaluation.evaluator]: \u001b[0mInference done 3040/4024. 0.0668 s / img. ETA=0:01:07\n",
      "\u001b[32m[06/26 23:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 3092/4024. 0.0673 s / img. ETA=0:01:04\n",
      "\u001b[32m[06/26 23:28:22 d2.evaluation.evaluator]: \u001b[0mInference done 3145/4024. 0.0678 s / img. ETA=0:01:00\n",
      "\u001b[32m[06/26 23:28:27 d2.evaluation.evaluator]: \u001b[0mInference done 3198/4024. 0.0683 s / img. ETA=0:00:57\n",
      "\u001b[32m[06/26 23:28:32 d2.evaluation.evaluator]: \u001b[0mInference done 3250/4024. 0.0687 s / img. ETA=0:00:54\n",
      "\u001b[32m[06/26 23:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 3299/4024. 0.0692 s / img. ETA=0:00:51\n",
      "\u001b[32m[06/26 23:28:43 d2.evaluation.evaluator]: \u001b[0mInference done 3351/4024. 0.0696 s / img. ETA=0:00:47\n",
      "\u001b[32m[06/26 23:28:48 d2.evaluation.evaluator]: \u001b[0mInference done 3404/4024. 0.0700 s / img. ETA=0:00:44\n",
      "\u001b[32m[06/26 23:28:53 d2.evaluation.evaluator]: \u001b[0mInference done 3454/4024. 0.0704 s / img. ETA=0:00:40\n",
      "\u001b[32m[06/26 23:28:58 d2.evaluation.evaluator]: \u001b[0mInference done 3507/4024. 0.0708 s / img. ETA=0:00:37\n",
      "\u001b[32m[06/26 23:29:03 d2.evaluation.evaluator]: \u001b[0mInference done 3557/4024. 0.0712 s / img. ETA=0:00:33\n",
      "\u001b[32m[06/26 23:29:08 d2.evaluation.evaluator]: \u001b[0mInference done 3609/4024. 0.0715 s / img. ETA=0:00:30\n",
      "\u001b[32m[06/26 23:29:13 d2.evaluation.evaluator]: \u001b[0mInference done 3660/4024. 0.0719 s / img. ETA=0:00:26\n",
      "\u001b[32m[06/26 23:29:18 d2.evaluation.evaluator]: \u001b[0mInference done 3712/4024. 0.0722 s / img. ETA=0:00:22\n",
      "\u001b[32m[06/26 23:29:23 d2.evaluation.evaluator]: \u001b[0mInference done 3765/4024. 0.0726 s / img. ETA=0:00:19\n",
      "\u001b[32m[06/26 23:29:28 d2.evaluation.evaluator]: \u001b[0mInference done 3815/4024. 0.0729 s / img. ETA=0:00:15\n",
      "\u001b[32m[06/26 23:29:33 d2.evaluation.evaluator]: \u001b[0mInference done 3867/4024. 0.0732 s / img. ETA=0:00:11\n",
      "\u001b[32m[06/26 23:29:38 d2.evaluation.evaluator]: \u001b[0mInference done 3917/4024. 0.0736 s / img. ETA=0:00:08\n",
      "\u001b[32m[06/26 23:29:43 d2.evaluation.evaluator]: \u001b[0mInference done 3969/4024. 0.0739 s / img. ETA=0:00:04\n",
      "\u001b[32m[06/26 23:29:48 d2.evaluation.evaluator]: \u001b[0mInference done 4020/4024. 0.0742 s / img. ETA=0:00:00\n",
      "\u001b[32m[06/26 23:29:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:05:03.757768 (0.075580 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:29:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:04:58 (0.074188 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:29:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/26 23:29:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/coco_instances_results.json\n",
      "\u001b[32m[06/26 23:29:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.99s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.24s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.041\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.023\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.015\n",
      "\u001b[32m[06/26 23:29:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 1.416 | 4.147  | 0.643  | 1.211 | 1.748 | 1.782 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4024it [00:06, 644.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/26 23:30:02 d2.data.common]: \u001b[0mSerializing 4024 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/26 23:30:02 d2.data.common]: \u001b[0mSerialized dataset takes 1.47 MiB\n",
      "\u001b[32m[06/26 23:30:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 4024 images\n",
      "\u001b[32m[06/26 23:30:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/4024. 0.1138 s / img. ETA=0:07:41\n",
      "\u001b[32m[06/26 23:30:08 d2.evaluation.evaluator]: \u001b[0mInference done 64/4024. 0.0975 s / img. ETA=0:06:31\n",
      "\u001b[32m[06/26 23:30:13 d2.evaluation.evaluator]: \u001b[0mInference done 117/4024. 0.0962 s / img. ETA=0:06:21\n",
      "\u001b[32m[06/26 23:30:18 d2.evaluation.evaluator]: \u001b[0mInference done 168/4024. 0.0966 s / img. ETA=0:06:17\n",
      "\u001b[32m[06/26 23:30:23 d2.evaluation.evaluator]: \u001b[0mInference done 221/4024. 0.0964 s / img. ETA=0:06:11\n",
      "\u001b[32m[06/26 23:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 271/4024. 0.0968 s / img. ETA=0:06:08\n",
      "\u001b[32m[06/26 23:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 324/4024. 0.0962 s / img. ETA=0:06:00\n",
      "\u001b[32m[06/26 23:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 375/4024. 0.0963 s / img. ETA=0:05:56\n",
      "\u001b[32m[06/26 23:30:43 d2.evaluation.evaluator]: \u001b[0mInference done 426/4024. 0.0965 s / img. ETA=0:05:51\n",
      "\u001b[32m[06/26 23:30:49 d2.evaluation.evaluator]: \u001b[0mInference done 479/4024. 0.0963 s / img. ETA=0:05:45\n",
      "\u001b[32m[06/26 23:30:54 d2.evaluation.evaluator]: \u001b[0mInference done 529/4024. 0.0966 s / img. ETA=0:05:42\n",
      "\u001b[32m[06/26 23:30:59 d2.evaluation.evaluator]: \u001b[0mInference done 582/4024. 0.0966 s / img. ETA=0:05:36\n",
      "\u001b[32m[06/26 23:31:04 d2.evaluation.evaluator]: \u001b[0mInference done 635/4024. 0.0963 s / img. ETA=0:05:30\n",
      "\u001b[32m[06/26 23:31:09 d2.evaluation.evaluator]: \u001b[0mInference done 687/4024. 0.0962 s / img. ETA=0:05:25\n",
      "\u001b[32m[06/26 23:31:14 d2.evaluation.evaluator]: \u001b[0mInference done 739/4024. 0.0963 s / img. ETA=0:05:20\n",
      "\u001b[32m[06/26 23:31:19 d2.evaluation.evaluator]: \u001b[0mInference done 791/4024. 0.0962 s / img. ETA=0:05:15\n",
      "\u001b[32m[06/26 23:31:24 d2.evaluation.evaluator]: \u001b[0mInference done 841/4024. 0.0964 s / img. ETA=0:05:10\n",
      "\u001b[32m[06/26 23:31:29 d2.evaluation.evaluator]: \u001b[0mInference done 893/4024. 0.0963 s / img. ETA=0:05:05\n",
      "\u001b[32m[06/26 23:31:34 d2.evaluation.evaluator]: \u001b[0mInference done 945/4024. 0.0963 s / img. ETA=0:05:00\n",
      "\u001b[32m[06/26 23:31:39 d2.evaluation.evaluator]: \u001b[0mInference done 997/4024. 0.0963 s / img. ETA=0:04:55\n",
      "\u001b[32m[06/26 23:31:44 d2.evaluation.evaluator]: \u001b[0mInference done 1050/4024. 0.0962 s / img. ETA=0:04:50\n",
      "\u001b[32m[06/26 23:31:49 d2.evaluation.evaluator]: \u001b[0mInference done 1100/4024. 0.0964 s / img. ETA=0:04:45\n",
      "\u001b[32m[06/26 23:31:54 d2.evaluation.evaluator]: \u001b[0mInference done 1152/4024. 0.0964 s / img. ETA=0:04:40\n",
      "\u001b[32m[06/26 23:31:59 d2.evaluation.evaluator]: \u001b[0mInference done 1203/4024. 0.0964 s / img. ETA=0:04:35\n",
      "\u001b[32m[06/26 23:32:04 d2.evaluation.evaluator]: \u001b[0mInference done 1254/4024. 0.0964 s / img. ETA=0:04:30\n",
      "\u001b[32m[06/26 23:32:09 d2.evaluation.evaluator]: \u001b[0mInference done 1306/4024. 0.0965 s / img. ETA=0:04:25\n",
      "\u001b[32m[06/26 23:32:15 d2.evaluation.evaluator]: \u001b[0mInference done 1359/4024. 0.0964 s / img. ETA=0:04:20\n",
      "\u001b[32m[06/26 23:32:20 d2.evaluation.evaluator]: \u001b[0mInference done 1409/4024. 0.0965 s / img. ETA=0:04:15\n",
      "\u001b[32m[06/26 23:32:25 d2.evaluation.evaluator]: \u001b[0mInference done 1462/4024. 0.0965 s / img. ETA=0:04:10\n",
      "\u001b[32m[06/26 23:32:30 d2.evaluation.evaluator]: \u001b[0mInference done 1513/4024. 0.0965 s / img. ETA=0:04:05\n",
      "\u001b[32m[06/26 23:32:35 d2.evaluation.evaluator]: \u001b[0mInference done 1565/4024. 0.0965 s / img. ETA=0:04:00\n",
      "\u001b[32m[06/26 23:32:40 d2.evaluation.evaluator]: \u001b[0mInference done 1618/4024. 0.0964 s / img. ETA=0:03:55\n",
      "\u001b[32m[06/26 23:32:45 d2.evaluation.evaluator]: \u001b[0mInference done 1669/4024. 0.0964 s / img. ETA=0:03:50\n",
      "\u001b[32m[06/26 23:32:50 d2.evaluation.evaluator]: \u001b[0mInference done 1721/4024. 0.0965 s / img. ETA=0:03:45\n",
      "\u001b[32m[06/26 23:32:55 d2.evaluation.evaluator]: \u001b[0mInference done 1771/4024. 0.0965 s / img. ETA=0:03:40\n",
      "\u001b[32m[06/26 23:33:00 d2.evaluation.evaluator]: \u001b[0mInference done 1823/4024. 0.0966 s / img. ETA=0:03:35\n",
      "\u001b[32m[06/26 23:33:05 d2.evaluation.evaluator]: \u001b[0mInference done 1873/4024. 0.0966 s / img. ETA=0:03:30\n",
      "\u001b[32m[06/26 23:33:10 d2.evaluation.evaluator]: \u001b[0mInference done 1925/4024. 0.0966 s / img. ETA=0:03:25\n",
      "\u001b[32m[06/26 23:33:15 d2.evaluation.evaluator]: \u001b[0mInference done 1976/4024. 0.0966 s / img. ETA=0:03:20\n",
      "\u001b[32m[06/26 23:33:20 d2.evaluation.evaluator]: \u001b[0mInference done 2028/4024. 0.0966 s / img. ETA=0:03:15\n",
      "\u001b[32m[06/26 23:33:25 d2.evaluation.evaluator]: \u001b[0mInference done 2080/4024. 0.0966 s / img. ETA=0:03:10\n",
      "\u001b[32m[06/26 23:33:30 d2.evaluation.evaluator]: \u001b[0mInference done 2131/4024. 0.0966 s / img. ETA=0:03:05\n",
      "\u001b[32m[06/26 23:33:35 d2.evaluation.evaluator]: \u001b[0mInference done 2182/4024. 0.0966 s / img. ETA=0:03:00\n",
      "\u001b[32m[06/26 23:33:41 d2.evaluation.evaluator]: \u001b[0mInference done 2235/4024. 0.0966 s / img. ETA=0:02:55\n",
      "\u001b[32m[06/26 23:33:46 d2.evaluation.evaluator]: \u001b[0mInference done 2285/4024. 0.0966 s / img. ETA=0:02:50\n",
      "\u001b[32m[06/26 23:33:51 d2.evaluation.evaluator]: \u001b[0mInference done 2338/4024. 0.0966 s / img. ETA=0:02:45\n",
      "\u001b[32m[06/26 23:33:56 d2.evaluation.evaluator]: \u001b[0mInference done 2391/4024. 0.0965 s / img. ETA=0:02:39\n",
      "\u001b[32m[06/26 23:34:01 d2.evaluation.evaluator]: \u001b[0mInference done 2441/4024. 0.0965 s / img. ETA=0:02:34\n",
      "\u001b[32m[06/26 23:34:06 d2.evaluation.evaluator]: \u001b[0mInference done 2495/4024. 0.0964 s / img. ETA=0:02:29\n",
      "\u001b[32m[06/26 23:34:11 d2.evaluation.evaluator]: \u001b[0mInference done 2547/4024. 0.0964 s / img. ETA=0:02:24\n",
      "\u001b[32m[06/26 23:34:16 d2.evaluation.evaluator]: \u001b[0mInference done 2597/4024. 0.0965 s / img. ETA=0:02:19\n",
      "\u001b[32m[06/26 23:34:21 d2.evaluation.evaluator]: \u001b[0mInference done 2650/4024. 0.0964 s / img. ETA=0:02:14\n",
      "\u001b[32m[06/26 23:34:26 d2.evaluation.evaluator]: \u001b[0mInference done 2700/4024. 0.0965 s / img. ETA=0:02:09\n",
      "\u001b[32m[06/26 23:34:31 d2.evaluation.evaluator]: \u001b[0mInference done 2752/4024. 0.0964 s / img. ETA=0:02:04\n",
      "\u001b[32m[06/26 23:34:36 d2.evaluation.evaluator]: \u001b[0mInference done 2802/4024. 0.0965 s / img. ETA=0:01:59\n",
      "\u001b[32m[06/26 23:34:41 d2.evaluation.evaluator]: \u001b[0mInference done 2854/4024. 0.0965 s / img. ETA=0:01:54\n",
      "\u001b[32m[06/26 23:34:46 d2.evaluation.evaluator]: \u001b[0mInference done 2906/4024. 0.0965 s / img. ETA=0:01:49\n",
      "\u001b[32m[06/26 23:34:51 d2.evaluation.evaluator]: \u001b[0mInference done 2957/4024. 0.0965 s / img. ETA=0:01:44\n",
      "\u001b[32m[06/26 23:34:56 d2.evaluation.evaluator]: \u001b[0mInference done 3008/4024. 0.0965 s / img. ETA=0:01:39\n",
      "\u001b[32m[06/26 23:35:01 d2.evaluation.evaluator]: \u001b[0mInference done 3059/4024. 0.0965 s / img. ETA=0:01:34\n",
      "\u001b[32m[06/26 23:35:06 d2.evaluation.evaluator]: \u001b[0mInference done 3112/4024. 0.0965 s / img. ETA=0:01:29\n",
      "\u001b[32m[06/26 23:35:11 d2.evaluation.evaluator]: \u001b[0mInference done 3161/4024. 0.0966 s / img. ETA=0:01:24\n",
      "\u001b[32m[06/26 23:35:16 d2.evaluation.evaluator]: \u001b[0mInference done 3214/4024. 0.0965 s / img. ETA=0:01:19\n",
      "\u001b[32m[06/26 23:35:21 d2.evaluation.evaluator]: \u001b[0mInference done 3266/4024. 0.0965 s / img. ETA=0:01:14\n",
      "\u001b[32m[06/26 23:35:26 d2.evaluation.evaluator]: \u001b[0mInference done 3316/4024. 0.0966 s / img. ETA=0:01:09\n",
      "\u001b[32m[06/26 23:35:31 d2.evaluation.evaluator]: \u001b[0mInference done 3367/4024. 0.0966 s / img. ETA=0:01:04\n",
      "\u001b[32m[06/26 23:35:37 d2.evaluation.evaluator]: \u001b[0mInference done 3418/4024. 0.0966 s / img. ETA=0:00:59\n",
      "\u001b[32m[06/26 23:35:42 d2.evaluation.evaluator]: \u001b[0mInference done 3469/4024. 0.0966 s / img. ETA=0:00:54\n",
      "\u001b[32m[06/26 23:35:47 d2.evaluation.evaluator]: \u001b[0mInference done 3521/4024. 0.0966 s / img. ETA=0:00:49\n",
      "\u001b[32m[06/26 23:35:52 d2.evaluation.evaluator]: \u001b[0mInference done 3574/4024. 0.0966 s / img. ETA=0:00:44\n",
      "\u001b[32m[06/26 23:35:57 d2.evaluation.evaluator]: \u001b[0mInference done 3624/4024. 0.0966 s / img. ETA=0:00:39\n",
      "\u001b[32m[06/26 23:36:02 d2.evaluation.evaluator]: \u001b[0mInference done 3677/4024. 0.0966 s / img. ETA=0:00:33\n",
      "\u001b[32m[06/26 23:36:07 d2.evaluation.evaluator]: \u001b[0mInference done 3728/4024. 0.0966 s / img. ETA=0:00:28\n",
      "\u001b[32m[06/26 23:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 3779/4024. 0.0966 s / img. ETA=0:00:23\n",
      "\u001b[32m[06/26 23:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 3829/4024. 0.0966 s / img. ETA=0:00:19\n",
      "\u001b[32m[06/26 23:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 3882/4024. 0.0966 s / img. ETA=0:00:13\n",
      "\u001b[32m[06/26 23:36:27 d2.evaluation.evaluator]: \u001b[0mInference done 3935/4024. 0.0966 s / img. ETA=0:00:08\n",
      "\u001b[32m[06/26 23:36:32 d2.evaluation.evaluator]: \u001b[0mInference done 3985/4024. 0.0966 s / img. ETA=0:00:03\n",
      "\u001b[32m[06/26 23:36:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:06:33.706698 (0.097961 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:36:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:06:28 (0.096599 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:36:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/26 23:36:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/coco_instances_results.json\n",
      "\u001b[32m[06/26 23:36:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.93s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.14s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.034\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.019\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.037\n",
      "\u001b[32m[06/26 23:36:37 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 1.475 | 3.207  | 1.027  | 1.507 | 1.449 | 3.440 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4024it [00:06, 641.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/26 23:36:48 d2.data.common]: \u001b[0mSerializing 4024 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/26 23:36:48 d2.data.common]: \u001b[0mSerialized dataset takes 1.47 MiB\n",
      "\u001b[32m[06/26 23:36:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 4024 images\n",
      "\u001b[32m[06/26 23:36:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/4024. 0.1089 s / img. ETA=0:07:21\n",
      "\u001b[32m[06/26 23:36:54 d2.evaluation.evaluator]: \u001b[0mInference done 61/4024. 0.0997 s / img. ETA=0:06:41\n",
      "\u001b[32m[06/26 23:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 110/4024. 0.1002 s / img. ETA=0:06:38\n",
      "\u001b[32m[06/26 23:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 161/4024. 0.0995 s / img. ETA=0:06:30\n",
      "\u001b[32m[06/26 23:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 212/4024. 0.0988 s / img. ETA=0:06:22\n",
      "\u001b[32m[06/26 23:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 262/4024. 0.0988 s / img. ETA=0:06:17\n",
      "\u001b[32m[06/26 23:37:19 d2.evaluation.evaluator]: \u001b[0mInference done 312/4024. 0.0989 s / img. ETA=0:06:12\n",
      "\u001b[32m[06/26 23:37:24 d2.evaluation.evaluator]: \u001b[0mInference done 363/4024. 0.0987 s / img. ETA=0:06:06\n",
      "\u001b[32m[06/26 23:37:29 d2.evaluation.evaluator]: \u001b[0mInference done 414/4024. 0.0985 s / img. ETA=0:06:00\n",
      "\u001b[32m[06/26 23:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 465/4024. 0.0985 s / img. ETA=0:05:55\n",
      "\u001b[32m[06/26 23:37:40 d2.evaluation.evaluator]: \u001b[0mInference done 517/4024. 0.0984 s / img. ETA=0:05:50\n",
      "\u001b[32m[06/26 23:37:45 d2.evaluation.evaluator]: \u001b[0mInference done 566/4024. 0.0986 s / img. ETA=0:05:46\n",
      "\u001b[32m[06/26 23:37:50 d2.evaluation.evaluator]: \u001b[0mInference done 618/4024. 0.0984 s / img. ETA=0:05:40\n",
      "\u001b[32m[06/26 23:37:55 d2.evaluation.evaluator]: \u001b[0mInference done 668/4024. 0.0984 s / img. ETA=0:05:35\n",
      "\u001b[32m[06/26 23:38:00 d2.evaluation.evaluator]: \u001b[0mInference done 718/4024. 0.0984 s / img. ETA=0:05:30\n",
      "\u001b[32m[06/26 23:38:05 d2.evaluation.evaluator]: \u001b[0mInference done 768/4024. 0.0985 s / img. ETA=0:05:25\n",
      "\u001b[32m[06/26 23:38:10 d2.evaluation.evaluator]: \u001b[0mInference done 820/4024. 0.0984 s / img. ETA=0:05:19\n",
      "\u001b[32m[06/26 23:38:15 d2.evaluation.evaluator]: \u001b[0mInference done 870/4024. 0.0984 s / img. ETA=0:05:15\n",
      "\u001b[32m[06/26 23:38:20 d2.evaluation.evaluator]: \u001b[0mInference done 922/4024. 0.0983 s / img. ETA=0:05:09\n",
      "\u001b[32m[06/26 23:38:25 d2.evaluation.evaluator]: \u001b[0mInference done 972/4024. 0.0983 s / img. ETA=0:05:04\n",
      "\u001b[32m[06/26 23:38:30 d2.evaluation.evaluator]: \u001b[0mInference done 1025/4024. 0.0982 s / img. ETA=0:04:58\n",
      "\u001b[32m[06/26 23:38:35 d2.evaluation.evaluator]: \u001b[0mInference done 1076/4024. 0.0981 s / img. ETA=0:04:53\n",
      "\u001b[32m[06/26 23:38:40 d2.evaluation.evaluator]: \u001b[0mInference done 1126/4024. 0.0981 s / img. ETA=0:04:48\n",
      "\u001b[32m[06/26 23:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 1179/4024. 0.0980 s / img. ETA=0:04:42\n",
      "\u001b[32m[06/26 23:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 1230/4024. 0.0979 s / img. ETA=0:04:37\n",
      "\u001b[32m[06/26 23:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 1281/4024. 0.0980 s / img. ETA=0:04:32\n",
      "\u001b[32m[06/26 23:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 1334/4024. 0.0978 s / img. ETA=0:04:26\n",
      "\u001b[32m[06/26 23:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 1384/4024. 0.0979 s / img. ETA=0:04:22\n",
      "\u001b[32m[06/26 23:39:10 d2.evaluation.evaluator]: \u001b[0mInference done 1437/4024. 0.0977 s / img. ETA=0:04:16\n",
      "\u001b[32m[06/26 23:39:15 d2.evaluation.evaluator]: \u001b[0mInference done 1488/4024. 0.0977 s / img. ETA=0:04:11\n",
      "\u001b[32m[06/26 23:39:21 d2.evaluation.evaluator]: \u001b[0mInference done 1538/4024. 0.0978 s / img. ETA=0:04:06\n",
      "\u001b[32m[06/26 23:39:26 d2.evaluation.evaluator]: \u001b[0mInference done 1591/4024. 0.0977 s / img. ETA=0:04:01\n",
      "\u001b[32m[06/26 23:39:31 d2.evaluation.evaluator]: \u001b[0mInference done 1642/4024. 0.0977 s / img. ETA=0:03:56\n",
      "\u001b[32m[06/26 23:39:36 d2.evaluation.evaluator]: \u001b[0mInference done 1693/4024. 0.0977 s / img. ETA=0:03:51\n",
      "\u001b[32m[06/26 23:39:41 d2.evaluation.evaluator]: \u001b[0mInference done 1744/4024. 0.0976 s / img. ETA=0:03:45\n",
      "\u001b[32m[06/26 23:39:46 d2.evaluation.evaluator]: \u001b[0mInference done 1794/4024. 0.0977 s / img. ETA=0:03:41\n",
      "\u001b[32m[06/26 23:39:51 d2.evaluation.evaluator]: \u001b[0mInference done 1844/4024. 0.0977 s / img. ETA=0:03:36\n",
      "\u001b[32m[06/26 23:39:56 d2.evaluation.evaluator]: \u001b[0mInference done 1895/4024. 0.0978 s / img. ETA=0:03:31\n",
      "\u001b[32m[06/26 23:40:01 d2.evaluation.evaluator]: \u001b[0mInference done 1947/4024. 0.0977 s / img. ETA=0:03:25\n",
      "\u001b[32m[06/26 23:40:06 d2.evaluation.evaluator]: \u001b[0mInference done 1997/4024. 0.0977 s / img. ETA=0:03:20\n",
      "\u001b[32m[06/26 23:40:11 d2.evaluation.evaluator]: \u001b[0mInference done 2048/4024. 0.0977 s / img. ETA=0:03:15\n",
      "\u001b[32m[06/26 23:40:16 d2.evaluation.evaluator]: \u001b[0mInference done 2101/4024. 0.0976 s / img. ETA=0:03:10\n",
      "\u001b[32m[06/26 23:40:21 d2.evaluation.evaluator]: \u001b[0mInference done 2151/4024. 0.0977 s / img. ETA=0:03:05\n",
      "\u001b[32m[06/26 23:40:26 d2.evaluation.evaluator]: \u001b[0mInference done 2204/4024. 0.0976 s / img. ETA=0:03:00\n",
      "\u001b[32m[06/26 23:40:31 d2.evaluation.evaluator]: \u001b[0mInference done 2254/4024. 0.0977 s / img. ETA=0:02:55\n",
      "\u001b[32m[06/26 23:40:36 d2.evaluation.evaluator]: \u001b[0mInference done 2306/4024. 0.0976 s / img. ETA=0:02:50\n",
      "\u001b[32m[06/26 23:40:41 d2.evaluation.evaluator]: \u001b[0mInference done 2357/4024. 0.0976 s / img. ETA=0:02:45\n",
      "\u001b[32m[06/26 23:40:46 d2.evaluation.evaluator]: \u001b[0mInference done 2407/4024. 0.0976 s / img. ETA=0:02:40\n",
      "\u001b[32m[06/26 23:40:51 d2.evaluation.evaluator]: \u001b[0mInference done 2458/4024. 0.0976 s / img. ETA=0:02:35\n",
      "\u001b[32m[06/26 23:40:56 d2.evaluation.evaluator]: \u001b[0mInference done 2508/4024. 0.0977 s / img. ETA=0:02:30\n",
      "\u001b[32m[06/26 23:41:01 d2.evaluation.evaluator]: \u001b[0mInference done 2558/4024. 0.0977 s / img. ETA=0:02:25\n",
      "\u001b[32m[06/26 23:41:07 d2.evaluation.evaluator]: \u001b[0mInference done 2609/4024. 0.0977 s / img. ETA=0:02:20\n",
      "\u001b[32m[06/26 23:41:12 d2.evaluation.evaluator]: \u001b[0mInference done 2661/4024. 0.0977 s / img. ETA=0:02:15\n",
      "\u001b[32m[06/26 23:41:17 d2.evaluation.evaluator]: \u001b[0mInference done 2711/4024. 0.0977 s / img. ETA=0:02:10\n",
      "\u001b[32m[06/26 23:41:22 d2.evaluation.evaluator]: \u001b[0mInference done 2762/4024. 0.0977 s / img. ETA=0:02:05\n",
      "\u001b[32m[06/26 23:41:27 d2.evaluation.evaluator]: \u001b[0mInference done 2812/4024. 0.0977 s / img. ETA=0:02:00\n",
      "\u001b[32m[06/26 23:41:32 d2.evaluation.evaluator]: \u001b[0mInference done 2865/4024. 0.0977 s / img. ETA=0:01:54\n",
      "\u001b[32m[06/26 23:41:37 d2.evaluation.evaluator]: \u001b[0mInference done 2918/4024. 0.0976 s / img. ETA=0:01:49\n",
      "\u001b[32m[06/26 23:41:42 d2.evaluation.evaluator]: \u001b[0mInference done 2971/4024. 0.0976 s / img. ETA=0:01:44\n",
      "\u001b[32m[06/26 23:41:47 d2.evaluation.evaluator]: \u001b[0mInference done 3023/4024. 0.0975 s / img. ETA=0:01:39\n",
      "\u001b[32m[06/26 23:41:52 d2.evaluation.evaluator]: \u001b[0mInference done 3073/4024. 0.0976 s / img. ETA=0:01:34\n",
      "\u001b[32m[06/26 23:41:57 d2.evaluation.evaluator]: \u001b[0mInference done 3125/4024. 0.0976 s / img. ETA=0:01:28\n",
      "\u001b[32m[06/26 23:42:02 d2.evaluation.evaluator]: \u001b[0mInference done 3177/4024. 0.0976 s / img. ETA=0:01:23\n",
      "\u001b[32m[06/26 23:42:07 d2.evaluation.evaluator]: \u001b[0mInference done 3229/4024. 0.0975 s / img. ETA=0:01:18\n",
      "\u001b[32m[06/26 23:42:12 d2.evaluation.evaluator]: \u001b[0mInference done 3278/4024. 0.0976 s / img. ETA=0:01:13\n",
      "\u001b[32m[06/26 23:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 3330/4024. 0.0976 s / img. ETA=0:01:08\n",
      "\u001b[32m[06/26 23:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 3380/4024. 0.0976 s / img. ETA=0:01:03\n",
      "\u001b[32m[06/26 23:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 3432/4024. 0.0976 s / img. ETA=0:00:58\n",
      "\u001b[32m[06/26 23:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 3484/4024. 0.0975 s / img. ETA=0:00:53\n",
      "\u001b[32m[06/26 23:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 3533/4024. 0.0976 s / img. ETA=0:00:48\n",
      "\u001b[32m[06/26 23:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 3585/4024. 0.0976 s / img. ETA=0:00:43\n",
      "\u001b[32m[06/26 23:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 3636/4024. 0.0976 s / img. ETA=0:00:38\n",
      "\u001b[32m[06/26 23:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 3687/4024. 0.0976 s / img. ETA=0:00:33\n",
      "\u001b[32m[06/26 23:42:58 d2.evaluation.evaluator]: \u001b[0mInference done 3739/4024. 0.0976 s / img. ETA=0:00:28\n",
      "\u001b[32m[06/26 23:43:03 d2.evaluation.evaluator]: \u001b[0mInference done 3790/4024. 0.0976 s / img. ETA=0:00:23\n",
      "\u001b[32m[06/26 23:43:08 d2.evaluation.evaluator]: \u001b[0mInference done 3841/4024. 0.0976 s / img. ETA=0:00:18\n",
      "\u001b[32m[06/26 23:43:13 d2.evaluation.evaluator]: \u001b[0mInference done 3893/4024. 0.0976 s / img. ETA=0:00:12\n",
      "\u001b[32m[06/26 23:43:18 d2.evaluation.evaluator]: \u001b[0mInference done 3942/4024. 0.0976 s / img. ETA=0:00:08\n",
      "\u001b[32m[06/26 23:43:23 d2.evaluation.evaluator]: \u001b[0mInference done 3991/4024. 0.0976 s / img. ETA=0:00:03\n",
      "\u001b[32m[06/26 23:43:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:06:38.181153 (0.099075 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:43:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:06:32 (0.097648 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:43:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/26 23:43:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/coco_instances_results.json\n",
      "\u001b[32m[06/26 23:43:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.17s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.082\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.029\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.046\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.028\n",
      "\u001b[32m[06/26 23:43:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 2.780 | 8.202  | 0.723  | 2.430 | 3.665 | 2.919 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4024it [00:06, 662.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/26 23:43:40 d2.data.common]: \u001b[0mSerializing 4024 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/26 23:43:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.47 MiB\n",
      "\u001b[32m[06/26 23:43:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 4024 images\n",
      "\u001b[32m[06/26 23:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/4024. 0.1051 s / img. ETA=0:07:06\n",
      "\u001b[32m[06/26 23:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 60/4024. 0.1022 s / img. ETA=0:06:50\n",
      "\u001b[32m[06/26 23:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 111/4024. 0.0997 s / img. ETA=0:06:35\n",
      "\u001b[32m[06/26 23:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 160/4024. 0.1003 s / img. ETA=0:06:32\n",
      "\u001b[32m[06/26 23:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 212/4024. 0.0992 s / img. ETA=0:06:23\n",
      "\u001b[32m[06/26 23:44:06 d2.evaluation.evaluator]: \u001b[0mInference done 262/4024. 0.0992 s / img. ETA=0:06:18\n",
      "\u001b[32m[06/26 23:44:11 d2.evaluation.evaluator]: \u001b[0mInference done 314/4024. 0.0986 s / img. ETA=0:06:10\n",
      "\u001b[32m[06/26 23:44:16 d2.evaluation.evaluator]: \u001b[0mInference done 366/4024. 0.0982 s / img. ETA=0:06:04\n",
      "\u001b[32m[06/26 23:44:21 d2.evaluation.evaluator]: \u001b[0mInference done 416/4024. 0.0984 s / img. ETA=0:05:59\n",
      "\u001b[32m[06/26 23:44:26 d2.evaluation.evaluator]: \u001b[0mInference done 467/4024. 0.0982 s / img. ETA=0:05:54\n",
      "\u001b[32m[06/26 23:44:31 d2.evaluation.evaluator]: \u001b[0mInference done 516/4024. 0.0984 s / img. ETA=0:05:50\n",
      "\u001b[32m[06/26 23:44:36 d2.evaluation.evaluator]: \u001b[0mInference done 569/4024. 0.0981 s / img. ETA=0:05:43\n",
      "\u001b[32m[06/26 23:44:41 d2.evaluation.evaluator]: \u001b[0mInference done 619/4024. 0.0983 s / img. ETA=0:05:39\n",
      "\u001b[32m[06/26 23:44:46 d2.evaluation.evaluator]: \u001b[0mInference done 672/4024. 0.0980 s / img. ETA=0:05:33\n",
      "\u001b[32m[06/26 23:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 722/4024. 0.0980 s / img. ETA=0:05:28\n",
      "\u001b[32m[06/26 23:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 773/4024. 0.0981 s / img. ETA=0:05:23\n",
      "\u001b[32m[06/26 23:45:02 d2.evaluation.evaluator]: \u001b[0mInference done 824/4024. 0.0981 s / img. ETA=0:05:18\n",
      "\u001b[32m[06/26 23:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 876/4024. 0.0980 s / img. ETA=0:05:12\n",
      "\u001b[32m[06/26 23:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 928/4024. 0.0978 s / img. ETA=0:05:07\n",
      "\u001b[32m[06/26 23:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 979/4024. 0.0978 s / img. ETA=0:05:02\n",
      "\u001b[32m[06/26 23:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 1031/4024. 0.0978 s / img. ETA=0:04:56\n",
      "\u001b[32m[06/26 23:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 1081/4024. 0.0978 s / img. ETA=0:04:51\n",
      "\u001b[32m[06/26 23:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 1134/4024. 0.0977 s / img. ETA=0:04:46\n",
      "\u001b[32m[06/26 23:45:37 d2.evaluation.evaluator]: \u001b[0mInference done 1185/4024. 0.0977 s / img. ETA=0:04:41\n",
      "\u001b[32m[06/26 23:45:42 d2.evaluation.evaluator]: \u001b[0mInference done 1236/4024. 0.0977 s / img. ETA=0:04:36\n",
      "\u001b[32m[06/26 23:45:47 d2.evaluation.evaluator]: \u001b[0mInference done 1289/4024. 0.0976 s / img. ETA=0:04:30\n",
      "\u001b[32m[06/26 23:45:52 d2.evaluation.evaluator]: \u001b[0mInference done 1339/4024. 0.0977 s / img. ETA=0:04:26\n",
      "\u001b[32m[06/26 23:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 1391/4024. 0.0977 s / img. ETA=0:04:20\n",
      "\u001b[32m[06/26 23:46:03 d2.evaluation.evaluator]: \u001b[0mInference done 1443/4024. 0.0977 s / img. ETA=0:04:15\n",
      "\u001b[32m[06/26 23:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 1496/4024. 0.0976 s / img. ETA=0:04:10\n",
      "\u001b[32m[06/26 23:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 1546/4024. 0.0976 s / img. ETA=0:04:05\n",
      "\u001b[32m[06/26 23:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 1598/4024. 0.0976 s / img. ETA=0:04:00\n",
      "\u001b[32m[06/26 23:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 1649/4024. 0.0976 s / img. ETA=0:03:55\n",
      "\u001b[32m[06/26 23:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 1700/4024. 0.0976 s / img. ETA=0:03:50\n",
      "\u001b[32m[06/26 23:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 1752/4024. 0.0975 s / img. ETA=0:03:44\n",
      "\u001b[32m[06/26 23:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 1802/4024. 0.0976 s / img. ETA=0:03:40\n",
      "\u001b[32m[06/26 23:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 1854/4024. 0.0976 s / img. ETA=0:03:34\n",
      "\u001b[32m[06/26 23:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 1904/4024. 0.0976 s / img. ETA=0:03:29\n",
      "\u001b[32m[06/26 23:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 1956/4024. 0.0976 s / img. ETA=0:03:24\n",
      "\u001b[32m[06/26 23:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 2005/4024. 0.0977 s / img. ETA=0:03:20\n",
      "\u001b[32m[06/26 23:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 2057/4024. 0.0976 s / img. ETA=0:03:14\n",
      "\u001b[32m[06/26 23:47:08 d2.evaluation.evaluator]: \u001b[0mInference done 2108/4024. 0.0976 s / img. ETA=0:03:09\n",
      "\u001b[32m[06/26 23:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 2159/4024. 0.0976 s / img. ETA=0:03:04\n",
      "\u001b[32m[06/26 23:47:18 d2.evaluation.evaluator]: \u001b[0mInference done 2210/4024. 0.0976 s / img. ETA=0:02:59\n",
      "\u001b[32m[06/26 23:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 2259/4024. 0.0977 s / img. ETA=0:02:54\n",
      "\u001b[32m[06/26 23:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 2311/4024. 0.0976 s / img. ETA=0:02:49\n",
      "\u001b[32m[06/26 23:47:34 d2.evaluation.evaluator]: \u001b[0mInference done 2361/4024. 0.0977 s / img. ETA=0:02:44\n",
      "\u001b[32m[06/26 23:47:39 d2.evaluation.evaluator]: \u001b[0mInference done 2413/4024. 0.0977 s / img. ETA=0:02:39\n",
      "\u001b[32m[06/26 23:47:44 d2.evaluation.evaluator]: \u001b[0mInference done 2463/4024. 0.0977 s / img. ETA=0:02:34\n",
      "\u001b[32m[06/26 23:47:49 d2.evaluation.evaluator]: \u001b[0mInference done 2515/4024. 0.0977 s / img. ETA=0:02:29\n",
      "\u001b[32m[06/26 23:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 2564/4024. 0.0978 s / img. ETA=0:02:24\n",
      "\u001b[32m[06/26 23:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 2615/4024. 0.0978 s / img. ETA=0:02:19\n",
      "\u001b[32m[06/26 23:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 2664/4024. 0.0978 s / img. ETA=0:02:14\n",
      "\u001b[32m[06/26 23:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 2716/4024. 0.0978 s / img. ETA=0:02:09\n",
      "\u001b[32m[06/26 23:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 2769/4024. 0.0978 s / img. ETA=0:02:04\n",
      "\u001b[32m[06/26 23:48:19 d2.evaluation.evaluator]: \u001b[0mInference done 2820/4024. 0.0978 s / img. ETA=0:01:59\n",
      "\u001b[32m[06/26 23:48:24 d2.evaluation.evaluator]: \u001b[0mInference done 2870/4024. 0.0978 s / img. ETA=0:01:54\n",
      "\u001b[32m[06/26 23:48:29 d2.evaluation.evaluator]: \u001b[0mInference done 2920/4024. 0.0978 s / img. ETA=0:01:49\n",
      "\u001b[32m[06/26 23:48:34 d2.evaluation.evaluator]: \u001b[0mInference done 2971/4024. 0.0978 s / img. ETA=0:01:44\n",
      "\u001b[32m[06/26 23:48:39 d2.evaluation.evaluator]: \u001b[0mInference done 3022/4024. 0.0978 s / img. ETA=0:01:39\n",
      "\u001b[32m[06/26 23:48:44 d2.evaluation.evaluator]: \u001b[0mInference done 3072/4024. 0.0978 s / img. ETA=0:01:34\n",
      "\u001b[32m[06/26 23:48:49 d2.evaluation.evaluator]: \u001b[0mInference done 3125/4024. 0.0978 s / img. ETA=0:01:29\n",
      "\u001b[32m[06/26 23:48:55 d2.evaluation.evaluator]: \u001b[0mInference done 3176/4024. 0.0978 s / img. ETA=0:01:24\n",
      "\u001b[32m[06/26 23:49:00 d2.evaluation.evaluator]: \u001b[0mInference done 3227/4024. 0.0978 s / img. ETA=0:01:19\n",
      "\u001b[32m[06/26 23:49:05 d2.evaluation.evaluator]: \u001b[0mInference done 3277/4024. 0.0978 s / img. ETA=0:01:14\n",
      "\u001b[32m[06/26 23:49:10 d2.evaluation.evaluator]: \u001b[0mInference done 3330/4024. 0.0978 s / img. ETA=0:01:08\n",
      "\u001b[32m[06/26 23:49:15 d2.evaluation.evaluator]: \u001b[0mInference done 3380/4024. 0.0978 s / img. ETA=0:01:03\n",
      "\u001b[32m[06/26 23:49:20 d2.evaluation.evaluator]: \u001b[0mInference done 3430/4024. 0.0978 s / img. ETA=0:00:58\n",
      "\u001b[32m[06/26 23:49:25 d2.evaluation.evaluator]: \u001b[0mInference done 3483/4024. 0.0977 s / img. ETA=0:00:53\n",
      "\u001b[32m[06/26 23:49:30 d2.evaluation.evaluator]: \u001b[0mInference done 3534/4024. 0.0978 s / img. ETA=0:00:48\n",
      "\u001b[32m[06/26 23:49:35 d2.evaluation.evaluator]: \u001b[0mInference done 3585/4024. 0.0978 s / img. ETA=0:00:43\n",
      "\u001b[32m[06/26 23:49:40 d2.evaluation.evaluator]: \u001b[0mInference done 3636/4024. 0.0978 s / img. ETA=0:00:38\n",
      "\u001b[32m[06/26 23:49:45 d2.evaluation.evaluator]: \u001b[0mInference done 3687/4024. 0.0978 s / img. ETA=0:00:33\n",
      "\u001b[32m[06/26 23:49:50 d2.evaluation.evaluator]: \u001b[0mInference done 3737/4024. 0.0978 s / img. ETA=0:00:28\n",
      "\u001b[32m[06/26 23:49:55 d2.evaluation.evaluator]: \u001b[0mInference done 3789/4024. 0.0978 s / img. ETA=0:00:23\n",
      "\u001b[32m[06/26 23:50:00 d2.evaluation.evaluator]: \u001b[0mInference done 3842/4024. 0.0977 s / img. ETA=0:00:18\n",
      "\u001b[32m[06/26 23:50:05 d2.evaluation.evaluator]: \u001b[0mInference done 3893/4024. 0.0977 s / img. ETA=0:00:12\n",
      "\u001b[32m[06/26 23:50:11 d2.evaluation.evaluator]: \u001b[0mInference done 3944/4024. 0.0978 s / img. ETA=0:00:07\n",
      "\u001b[32m[06/26 23:50:16 d2.evaluation.evaluator]: \u001b[0mInference done 3995/4024. 0.0977 s / img. ETA=0:00:02\n",
      "\u001b[32m[06/26 23:50:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:06:38.508164 (0.099156 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:50:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:06:32 (0.097755 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:50:19 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/26 23:50:19 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/coco_instances_results.json\n",
      "\u001b[32m[06/26 23:50:19 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.17s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.098\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.041\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.059\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.048\n",
      "\u001b[32m[06/26 23:50:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 4.365 | 9.787  | 3.106  | 3.675 | 5.131 | 4.114 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4024it [00:06, 658.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/26 23:50:31 d2.data.common]: \u001b[0mSerializing 4024 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/26 23:50:31 d2.data.common]: \u001b[0mSerialized dataset takes 1.47 MiB\n",
      "\u001b[32m[06/26 23:50:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 4024 images\n",
      "\u001b[32m[06/26 23:50:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/4024. 0.1075 s / img. ETA=0:07:15\n",
      "\u001b[32m[06/26 23:50:37 d2.evaluation.evaluator]: \u001b[0mInference done 62/4024. 0.0982 s / img. ETA=0:06:34\n",
      "\u001b[32m[06/26 23:50:42 d2.evaluation.evaluator]: \u001b[0mInference done 113/4024. 0.0975 s / img. ETA=0:06:26\n",
      "\u001b[32m[06/26 23:50:47 d2.evaluation.evaluator]: \u001b[0mInference done 163/4024. 0.0980 s / img. ETA=0:06:23\n",
      "\u001b[32m[06/26 23:50:52 d2.evaluation.evaluator]: \u001b[0mInference done 215/4024. 0.0972 s / img. ETA=0:06:15\n",
      "\u001b[32m[06/26 23:50:57 d2.evaluation.evaluator]: \u001b[0mInference done 265/4024. 0.0975 s / img. ETA=0:06:11\n",
      "\u001b[32m[06/26 23:51:03 d2.evaluation.evaluator]: \u001b[0mInference done 318/4024. 0.0971 s / img. ETA=0:06:05\n",
      "\u001b[32m[06/26 23:51:08 d2.evaluation.evaluator]: \u001b[0mInference done 371/4024. 0.0969 s / img. ETA=0:05:59\n",
      "\u001b[32m[06/26 23:51:13 d2.evaluation.evaluator]: \u001b[0mInference done 423/4024. 0.0967 s / img. ETA=0:05:53\n",
      "\u001b[32m[06/26 23:51:18 d2.evaluation.evaluator]: \u001b[0mInference done 473/4024. 0.0970 s / img. ETA=0:05:49\n",
      "\u001b[32m[06/26 23:51:23 d2.evaluation.evaluator]: \u001b[0mInference done 525/4024. 0.0969 s / img. ETA=0:05:43\n",
      "\u001b[32m[06/26 23:51:28 d2.evaluation.evaluator]: \u001b[0mInference done 574/4024. 0.0973 s / img. ETA=0:05:40\n",
      "\u001b[32m[06/26 23:51:33 d2.evaluation.evaluator]: \u001b[0mInference done 626/4024. 0.0971 s / img. ETA=0:05:34\n",
      "\u001b[32m[06/26 23:51:38 d2.evaluation.evaluator]: \u001b[0mInference done 676/4024. 0.0973 s / img. ETA=0:05:30\n",
      "\u001b[32m[06/26 23:51:43 d2.evaluation.evaluator]: \u001b[0mInference done 728/4024. 0.0973 s / img. ETA=0:05:25\n",
      "\u001b[32m[06/26 23:51:48 d2.evaluation.evaluator]: \u001b[0mInference done 778/4024. 0.0974 s / img. ETA=0:05:20\n",
      "\u001b[32m[06/26 23:51:53 d2.evaluation.evaluator]: \u001b[0mInference done 830/4024. 0.0973 s / img. ETA=0:05:15\n",
      "\u001b[32m[06/26 23:51:58 d2.evaluation.evaluator]: \u001b[0mInference done 882/4024. 0.0972 s / img. ETA=0:05:09\n",
      "\u001b[32m[06/26 23:52:03 d2.evaluation.evaluator]: \u001b[0mInference done 934/4024. 0.0972 s / img. ETA=0:05:04\n",
      "\u001b[32m[06/26 23:52:08 d2.evaluation.evaluator]: \u001b[0mInference done 985/4024. 0.0972 s / img. ETA=0:04:59\n",
      "\u001b[32m[06/26 23:52:13 d2.evaluation.evaluator]: \u001b[0mInference done 1036/4024. 0.0972 s / img. ETA=0:04:54\n",
      "\u001b[32m[06/26 23:52:18 d2.evaluation.evaluator]: \u001b[0mInference done 1087/4024. 0.0972 s / img. ETA=0:04:49\n",
      "\u001b[32m[06/26 23:52:23 d2.evaluation.evaluator]: \u001b[0mInference done 1137/4024. 0.0973 s / img. ETA=0:04:45\n",
      "\u001b[32m[06/26 23:52:29 d2.evaluation.evaluator]: \u001b[0mInference done 1188/4024. 0.0974 s / img. ETA=0:04:40\n",
      "\u001b[32m[06/26 23:52:34 d2.evaluation.evaluator]: \u001b[0mInference done 1238/4024. 0.0974 s / img. ETA=0:04:35\n",
      "\u001b[32m[06/26 23:52:39 d2.evaluation.evaluator]: \u001b[0mInference done 1290/4024. 0.0975 s / img. ETA=0:04:30\n",
      "\u001b[32m[06/26 23:52:44 d2.evaluation.evaluator]: \u001b[0mInference done 1340/4024. 0.0975 s / img. ETA=0:04:25\n",
      "\u001b[32m[06/26 23:52:49 d2.evaluation.evaluator]: \u001b[0mInference done 1391/4024. 0.0976 s / img. ETA=0:04:20\n",
      "\u001b[32m[06/26 23:52:54 d2.evaluation.evaluator]: \u001b[0mInference done 1443/4024. 0.0975 s / img. ETA=0:04:15\n",
      "\u001b[32m[06/26 23:52:59 d2.evaluation.evaluator]: \u001b[0mInference done 1493/4024. 0.0976 s / img. ETA=0:04:10\n",
      "\u001b[32m[06/26 23:53:04 d2.evaluation.evaluator]: \u001b[0mInference done 1545/4024. 0.0976 s / img. ETA=0:04:05\n",
      "\u001b[32m[06/26 23:53:09 d2.evaluation.evaluator]: \u001b[0mInference done 1595/4024. 0.0976 s / img. ETA=0:04:00\n",
      "\u001b[32m[06/26 23:53:14 d2.evaluation.evaluator]: \u001b[0mInference done 1647/4024. 0.0976 s / img. ETA=0:03:55\n",
      "\u001b[32m[06/26 23:53:19 d2.evaluation.evaluator]: \u001b[0mInference done 1696/4024. 0.0977 s / img. ETA=0:03:50\n",
      "\u001b[32m[06/26 23:53:24 d2.evaluation.evaluator]: \u001b[0mInference done 1747/4024. 0.0977 s / img. ETA=0:03:45\n",
      "\u001b[32m[06/26 23:53:29 d2.evaluation.evaluator]: \u001b[0mInference done 1797/4024. 0.0977 s / img. ETA=0:03:40\n",
      "\u001b[32m[06/26 23:53:34 d2.evaluation.evaluator]: \u001b[0mInference done 1848/4024. 0.0977 s / img. ETA=0:03:35\n",
      "\u001b[32m[06/26 23:53:39 d2.evaluation.evaluator]: \u001b[0mInference done 1899/4024. 0.0977 s / img. ETA=0:03:30\n",
      "\u001b[32m[06/26 23:53:45 d2.evaluation.evaluator]: \u001b[0mInference done 1949/4024. 0.0978 s / img. ETA=0:03:25\n",
      "\u001b[32m[06/26 23:53:50 d2.evaluation.evaluator]: \u001b[0mInference done 2000/4024. 0.0978 s / img. ETA=0:03:20\n",
      "\u001b[32m[06/26 23:53:55 d2.evaluation.evaluator]: \u001b[0mInference done 2051/4024. 0.0977 s / img. ETA=0:03:15\n",
      "\u001b[32m[06/26 23:54:00 d2.evaluation.evaluator]: \u001b[0mInference done 2102/4024. 0.0977 s / img. ETA=0:03:10\n",
      "\u001b[32m[06/26 23:54:05 d2.evaluation.evaluator]: \u001b[0mInference done 2155/4024. 0.0976 s / img. ETA=0:03:05\n",
      "\u001b[32m[06/26 23:54:10 d2.evaluation.evaluator]: \u001b[0mInference done 2205/4024. 0.0977 s / img. ETA=0:03:00\n",
      "\u001b[32m[06/26 23:54:15 d2.evaluation.evaluator]: \u001b[0mInference done 2255/4024. 0.0977 s / img. ETA=0:02:55\n",
      "\u001b[32m[06/26 23:54:20 d2.evaluation.evaluator]: \u001b[0mInference done 2307/4024. 0.0977 s / img. ETA=0:02:50\n",
      "\u001b[32m[06/26 23:54:25 d2.evaluation.evaluator]: \u001b[0mInference done 2357/4024. 0.0977 s / img. ETA=0:02:45\n",
      "\u001b[32m[06/26 23:54:30 d2.evaluation.evaluator]: \u001b[0mInference done 2410/4024. 0.0977 s / img. ETA=0:02:39\n",
      "\u001b[32m[06/26 23:54:35 d2.evaluation.evaluator]: \u001b[0mInference done 2462/4024. 0.0976 s / img. ETA=0:02:34\n",
      "\u001b[32m[06/26 23:54:40 d2.evaluation.evaluator]: \u001b[0mInference done 2513/4024. 0.0976 s / img. ETA=0:02:29\n",
      "\u001b[32m[06/26 23:54:45 d2.evaluation.evaluator]: \u001b[0mInference done 2563/4024. 0.0977 s / img. ETA=0:02:24\n",
      "\u001b[32m[06/26 23:54:50 d2.evaluation.evaluator]: \u001b[0mInference done 2614/4024. 0.0977 s / img. ETA=0:02:19\n",
      "\u001b[32m[06/26 23:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 2665/4024. 0.0977 s / img. ETA=0:02:14\n",
      "\u001b[32m[06/26 23:55:00 d2.evaluation.evaluator]: \u001b[0mInference done 2716/4024. 0.0977 s / img. ETA=0:02:09\n",
      "\u001b[32m[06/26 23:55:05 d2.evaluation.evaluator]: \u001b[0mInference done 2767/4024. 0.0977 s / img. ETA=0:02:04\n",
      "\u001b[32m[06/26 23:55:10 d2.evaluation.evaluator]: \u001b[0mInference done 2818/4024. 0.0977 s / img. ETA=0:01:59\n",
      "\u001b[32m[06/26 23:55:16 d2.evaluation.evaluator]: \u001b[0mInference done 2868/4024. 0.0977 s / img. ETA=0:01:54\n",
      "\u001b[32m[06/26 23:55:21 d2.evaluation.evaluator]: \u001b[0mInference done 2920/4024. 0.0977 s / img. ETA=0:01:49\n",
      "\u001b[32m[06/26 23:55:26 d2.evaluation.evaluator]: \u001b[0mInference done 2973/4024. 0.0977 s / img. ETA=0:01:44\n",
      "\u001b[32m[06/26 23:55:31 d2.evaluation.evaluator]: \u001b[0mInference done 3024/4024. 0.0977 s / img. ETA=0:01:39\n",
      "\u001b[32m[06/26 23:55:36 d2.evaluation.evaluator]: \u001b[0mInference done 3075/4024. 0.0977 s / img. ETA=0:01:34\n",
      "\u001b[32m[06/26 23:55:41 d2.evaluation.evaluator]: \u001b[0mInference done 3125/4024. 0.0977 s / img. ETA=0:01:29\n",
      "\u001b[32m[06/26 23:55:46 d2.evaluation.evaluator]: \u001b[0mInference done 3175/4024. 0.0977 s / img. ETA=0:01:24\n",
      "\u001b[32m[06/26 23:55:51 d2.evaluation.evaluator]: \u001b[0mInference done 3226/4024. 0.0978 s / img. ETA=0:01:19\n",
      "\u001b[32m[06/26 23:55:56 d2.evaluation.evaluator]: \u001b[0mInference done 3277/4024. 0.0977 s / img. ETA=0:01:14\n",
      "\u001b[32m[06/26 23:56:01 d2.evaluation.evaluator]: \u001b[0mInference done 3326/4024. 0.0978 s / img. ETA=0:01:09\n",
      "\u001b[32m[06/26 23:56:06 d2.evaluation.evaluator]: \u001b[0mInference done 3377/4024. 0.0978 s / img. ETA=0:01:04\n",
      "\u001b[32m[06/26 23:56:11 d2.evaluation.evaluator]: \u001b[0mInference done 3426/4024. 0.0978 s / img. ETA=0:00:59\n",
      "\u001b[32m[06/26 23:56:16 d2.evaluation.evaluator]: \u001b[0mInference done 3477/4024. 0.0978 s / img. ETA=0:00:54\n",
      "\u001b[32m[06/26 23:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 3526/4024. 0.0979 s / img. ETA=0:00:49\n",
      "\u001b[32m[06/26 23:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 3578/4024. 0.0979 s / img. ETA=0:00:44\n",
      "\u001b[32m[06/26 23:56:31 d2.evaluation.evaluator]: \u001b[0mInference done 3630/4024. 0.0978 s / img. ETA=0:00:39\n",
      "\u001b[32m[06/26 23:56:36 d2.evaluation.evaluator]: \u001b[0mInference done 3680/4024. 0.0979 s / img. ETA=0:00:34\n",
      "\u001b[32m[06/26 23:56:42 d2.evaluation.evaluator]: \u001b[0mInference done 3731/4024. 0.0979 s / img. ETA=0:00:29\n",
      "\u001b[32m[06/26 23:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 3783/4024. 0.0978 s / img. ETA=0:00:23\n",
      "\u001b[32m[06/26 23:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 3833/4024. 0.0978 s / img. ETA=0:00:18\n",
      "\u001b[32m[06/26 23:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 3885/4024. 0.0978 s / img. ETA=0:00:13\n",
      "\u001b[32m[06/26 23:57:02 d2.evaluation.evaluator]: \u001b[0mInference done 3937/4024. 0.0978 s / img. ETA=0:00:08\n",
      "\u001b[32m[06/26 23:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 3987/4024. 0.0978 s / img. ETA=0:00:03\n",
      "\u001b[32m[06/26 23:57:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:06:38.847069 (0.099240 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:57:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:06:33 (0.097821 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/26 23:57:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/26 23:57:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/coco_instances_results.json\n",
      "\u001b[32m[06/26 23:57:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.36s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.051\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.021\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.051\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.078\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.054\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.106\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.092\n",
      "\u001b[32m[06/26 23:57:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 5.073 | 13.344 | 2.119  | 3.704 | 6.697 | 7.707 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4024it [00:06, 639.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/26 23:57:24 d2.data.common]: \u001b[0mSerializing 4024 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/26 23:57:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.47 MiB\n",
      "\u001b[32m[06/26 23:57:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 4024 images\n",
      "\u001b[32m[06/26 23:57:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/4024. 0.1083 s / img. ETA=0:07:19\n",
      "\u001b[32m[06/26 23:57:30 d2.evaluation.evaluator]: \u001b[0mInference done 61/4024. 0.1017 s / img. ETA=0:06:49\n",
      "\u001b[32m[06/26 23:57:35 d2.evaluation.evaluator]: \u001b[0mInference done 113/4024. 0.0996 s / img. ETA=0:06:35\n",
      "\u001b[32m[06/26 23:57:40 d2.evaluation.evaluator]: \u001b[0mInference done 163/4024. 0.0996 s / img. ETA=0:06:30\n",
      "\u001b[32m[06/26 23:57:45 d2.evaluation.evaluator]: \u001b[0mInference done 215/4024. 0.0986 s / img. ETA=0:06:21\n",
      "\u001b[32m[06/26 23:57:50 d2.evaluation.evaluator]: \u001b[0mInference done 265/4024. 0.0987 s / img. ETA=0:06:16\n",
      "\u001b[32m[06/26 23:57:55 d2.evaluation.evaluator]: \u001b[0mInference done 318/4024. 0.0981 s / img. ETA=0:06:08\n",
      "\u001b[32m[06/26 23:58:01 d2.evaluation.evaluator]: \u001b[0mInference done 368/4024. 0.0986 s / img. ETA=0:06:05\n",
      "\u001b[32m[06/26 23:58:06 d2.evaluation.evaluator]: \u001b[0mInference done 420/4024. 0.0981 s / img. ETA=0:05:58\n",
      "\u001b[32m[06/26 23:58:11 d2.evaluation.evaluator]: \u001b[0mInference done 471/4024. 0.0981 s / img. ETA=0:05:53\n",
      "\u001b[32m[06/26 23:58:16 d2.evaluation.evaluator]: \u001b[0mInference done 523/4024. 0.0980 s / img. ETA=0:05:48\n",
      "\u001b[32m[06/26 23:58:21 d2.evaluation.evaluator]: \u001b[0mInference done 575/4024. 0.0978 s / img. ETA=0:05:42\n",
      "\u001b[32m[06/26 23:58:26 d2.evaluation.evaluator]: \u001b[0mInference done 625/4024. 0.0981 s / img. ETA=0:05:38\n",
      "\u001b[32m[06/26 23:58:31 d2.evaluation.evaluator]: \u001b[0mInference done 676/4024. 0.0980 s / img. ETA=0:05:32\n",
      "\u001b[32m[06/26 23:58:36 d2.evaluation.evaluator]: \u001b[0mInference done 726/4024. 0.0981 s / img. ETA=0:05:28\n",
      "\u001b[32m[06/26 23:58:41 d2.evaluation.evaluator]: \u001b[0mInference done 778/4024. 0.0981 s / img. ETA=0:05:22\n",
      "\u001b[32m[06/26 23:58:46 d2.evaluation.evaluator]: \u001b[0mInference done 831/4024. 0.0979 s / img. ETA=0:05:17\n",
      "\u001b[32m[06/26 23:58:51 d2.evaluation.evaluator]: \u001b[0mInference done 883/4024. 0.0979 s / img. ETA=0:05:11\n",
      "\u001b[32m[06/26 23:58:56 d2.evaluation.evaluator]: \u001b[0mInference done 935/4024. 0.0977 s / img. ETA=0:05:06\n",
      "\u001b[32m[06/26 23:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 986/4024. 0.0978 s / img. ETA=0:05:01\n",
      "\u001b[32m[06/26 23:59:07 d2.evaluation.evaluator]: \u001b[0mInference done 1038/4024. 0.0977 s / img. ETA=0:04:56\n",
      "\u001b[32m[06/26 23:59:12 d2.evaluation.evaluator]: \u001b[0mInference done 1088/4024. 0.0978 s / img. ETA=0:04:51\n",
      "\u001b[32m[06/26 23:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 1139/4024. 0.0978 s / img. ETA=0:04:46\n",
      "\u001b[32m[06/26 23:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 1191/4024. 0.0977 s / img. ETA=0:04:40\n",
      "\u001b[32m[06/26 23:59:27 d2.evaluation.evaluator]: \u001b[0mInference done 1244/4024. 0.0976 s / img. ETA=0:04:35\n",
      "\u001b[32m[06/26 23:59:32 d2.evaluation.evaluator]: \u001b[0mInference done 1295/4024. 0.0976 s / img. ETA=0:04:30\n",
      "\u001b[32m[06/26 23:59:37 d2.evaluation.evaluator]: \u001b[0mInference done 1345/4024. 0.0976 s / img. ETA=0:04:25\n",
      "\u001b[32m[06/26 23:59:42 d2.evaluation.evaluator]: \u001b[0mInference done 1397/4024. 0.0976 s / img. ETA=0:04:19\n",
      "\u001b[32m[06/26 23:59:47 d2.evaluation.evaluator]: \u001b[0mInference done 1447/4024. 0.0976 s / img. ETA=0:04:15\n",
      "\u001b[32m[06/26 23:59:52 d2.evaluation.evaluator]: \u001b[0mInference done 1499/4024. 0.0975 s / img. ETA=0:04:09\n",
      "\u001b[32m[06/26 23:59:57 d2.evaluation.evaluator]: \u001b[0mInference done 1549/4024. 0.0976 s / img. ETA=0:04:05\n",
      "\u001b[32m[06/27 00:00:02 d2.evaluation.evaluator]: \u001b[0mInference done 1601/4024. 0.0976 s / img. ETA=0:03:59\n",
      "\u001b[32m[06/27 00:00:07 d2.evaluation.evaluator]: \u001b[0mInference done 1650/4024. 0.0976 s / img. ETA=0:03:55\n",
      "\u001b[32m[06/27 00:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 1702/4024. 0.0976 s / img. ETA=0:03:49\n",
      "\u001b[32m[06/27 00:00:17 d2.evaluation.evaluator]: \u001b[0mInference done 1752/4024. 0.0977 s / img. ETA=0:03:45\n",
      "\u001b[32m[06/27 00:00:22 d2.evaluation.evaluator]: \u001b[0mInference done 1805/4024. 0.0976 s / img. ETA=0:03:39\n",
      "\u001b[32m[06/27 00:00:27 d2.evaluation.evaluator]: \u001b[0mInference done 1857/4024. 0.0975 s / img. ETA=0:03:34\n",
      "\u001b[32m[06/27 00:00:32 d2.evaluation.evaluator]: \u001b[0mInference done 1907/4024. 0.0976 s / img. ETA=0:03:29\n",
      "\u001b[32m[06/27 00:00:38 d2.evaluation.evaluator]: \u001b[0mInference done 1957/4024. 0.0977 s / img. ETA=0:03:24\n",
      "\u001b[32m[06/27 00:00:43 d2.evaluation.evaluator]: \u001b[0mInference done 2009/4024. 0.0976 s / img. ETA=0:03:19\n",
      "\u001b[32m[06/27 00:00:48 d2.evaluation.evaluator]: \u001b[0mInference done 2059/4024. 0.0977 s / img. ETA=0:03:14\n",
      "\u001b[32m[06/27 00:00:53 d2.evaluation.evaluator]: \u001b[0mInference done 2111/4024. 0.0977 s / img. ETA=0:03:09\n",
      "\u001b[32m[06/27 00:00:58 d2.evaluation.evaluator]: \u001b[0mInference done 2163/4024. 0.0976 s / img. ETA=0:03:04\n",
      "\u001b[32m[06/27 00:01:03 d2.evaluation.evaluator]: \u001b[0mInference done 2213/4024. 0.0977 s / img. ETA=0:02:59\n",
      "\u001b[32m[06/27 00:01:08 d2.evaluation.evaluator]: \u001b[0mInference done 2264/4024. 0.0977 s / img. ETA=0:02:54\n",
      "\u001b[32m[06/27 00:01:13 d2.evaluation.evaluator]: \u001b[0mInference done 2316/4024. 0.0976 s / img. ETA=0:02:49\n",
      "\u001b[32m[06/27 00:01:18 d2.evaluation.evaluator]: \u001b[0mInference done 2367/4024. 0.0976 s / img. ETA=0:02:44\n",
      "\u001b[32m[06/27 00:01:23 d2.evaluation.evaluator]: \u001b[0mInference done 2418/4024. 0.0977 s / img. ETA=0:02:39\n",
      "\u001b[32m[06/27 00:01:28 d2.evaluation.evaluator]: \u001b[0mInference done 2471/4024. 0.0976 s / img. ETA=0:02:33\n",
      "\u001b[32m[06/27 00:01:33 d2.evaluation.evaluator]: \u001b[0mInference done 2521/4024. 0.0977 s / img. ETA=0:02:28\n",
      "\u001b[32m[06/27 00:01:38 d2.evaluation.evaluator]: \u001b[0mInference done 2573/4024. 0.0976 s / img. ETA=0:02:23\n",
      "\u001b[32m[06/27 00:01:44 d2.evaluation.evaluator]: \u001b[0mInference done 2625/4024. 0.0976 s / img. ETA=0:02:18\n",
      "\u001b[32m[06/27 00:01:49 d2.evaluation.evaluator]: \u001b[0mInference done 2676/4024. 0.0976 s / img. ETA=0:02:13\n",
      "\u001b[32m[06/27 00:01:54 d2.evaluation.evaluator]: \u001b[0mInference done 2727/4024. 0.0976 s / img. ETA=0:02:08\n",
      "\u001b[32m[06/27 00:01:59 d2.evaluation.evaluator]: \u001b[0mInference done 2779/4024. 0.0976 s / img. ETA=0:02:03\n",
      "\u001b[32m[06/27 00:02:04 d2.evaluation.evaluator]: \u001b[0mInference done 2830/4024. 0.0976 s / img. ETA=0:01:58\n",
      "\u001b[32m[06/27 00:02:09 d2.evaluation.evaluator]: \u001b[0mInference done 2880/4024. 0.0977 s / img. ETA=0:01:53\n",
      "\u001b[32m[06/27 00:02:14 d2.evaluation.evaluator]: \u001b[0mInference done 2931/4024. 0.0977 s / img. ETA=0:01:48\n",
      "\u001b[32m[06/27 00:02:19 d2.evaluation.evaluator]: \u001b[0mInference done 2981/4024. 0.0977 s / img. ETA=0:01:43\n",
      "\u001b[32m[06/27 00:02:24 d2.evaluation.evaluator]: \u001b[0mInference done 3032/4024. 0.0977 s / img. ETA=0:01:38\n",
      "\u001b[32m[06/27 00:02:29 d2.evaluation.evaluator]: \u001b[0mInference done 3084/4024. 0.0977 s / img. ETA=0:01:33\n",
      "\u001b[32m[06/27 00:02:34 d2.evaluation.evaluator]: \u001b[0mInference done 3135/4024. 0.0977 s / img. ETA=0:01:28\n",
      "\u001b[32m[06/27 00:02:39 d2.evaluation.evaluator]: \u001b[0mInference done 3185/4024. 0.0977 s / img. ETA=0:01:23\n",
      "\u001b[32m[06/27 00:02:44 d2.evaluation.evaluator]: \u001b[0mInference done 3237/4024. 0.0977 s / img. ETA=0:01:17\n",
      "\u001b[32m[06/27 00:02:49 d2.evaluation.evaluator]: \u001b[0mInference done 3290/4024. 0.0976 s / img. ETA=0:01:12\n",
      "\u001b[32m[06/27 00:02:55 d2.evaluation.evaluator]: \u001b[0mInference done 3340/4024. 0.0976 s / img. ETA=0:01:07\n",
      "\u001b[32m[06/27 00:03:00 d2.evaluation.evaluator]: \u001b[0mInference done 3392/4024. 0.0976 s / img. ETA=0:01:02\n",
      "\u001b[32m[06/27 00:03:05 d2.evaluation.evaluator]: \u001b[0mInference done 3442/4024. 0.0976 s / img. ETA=0:00:57\n",
      "\u001b[32m[06/27 00:03:10 d2.evaluation.evaluator]: \u001b[0mInference done 3493/4024. 0.0976 s / img. ETA=0:00:52\n",
      "\u001b[32m[06/27 00:03:15 d2.evaluation.evaluator]: \u001b[0mInference done 3542/4024. 0.0977 s / img. ETA=0:00:47\n",
      "\u001b[32m[06/27 00:03:20 d2.evaluation.evaluator]: \u001b[0mInference done 3594/4024. 0.0976 s / img. ETA=0:00:42\n",
      "\u001b[32m[06/27 00:03:25 d2.evaluation.evaluator]: \u001b[0mInference done 3644/4024. 0.0977 s / img. ETA=0:00:37\n",
      "\u001b[32m[06/27 00:03:30 d2.evaluation.evaluator]: \u001b[0mInference done 3697/4024. 0.0977 s / img. ETA=0:00:32\n",
      "\u001b[32m[06/27 00:03:35 d2.evaluation.evaluator]: \u001b[0mInference done 3749/4024. 0.0976 s / img. ETA=0:00:27\n",
      "\u001b[32m[06/27 00:03:40 d2.evaluation.evaluator]: \u001b[0mInference done 3799/4024. 0.0976 s / img. ETA=0:00:22\n",
      "\u001b[32m[06/27 00:03:45 d2.evaluation.evaluator]: \u001b[0mInference done 3851/4024. 0.0976 s / img. ETA=0:00:17\n",
      "\u001b[32m[06/27 00:03:50 d2.evaluation.evaluator]: \u001b[0mInference done 3901/4024. 0.0976 s / img. ETA=0:00:12\n",
      "\u001b[32m[06/27 00:03:55 d2.evaluation.evaluator]: \u001b[0mInference done 3954/4024. 0.0976 s / img. ETA=0:00:06\n",
      "\u001b[32m[06/27 00:04:00 d2.evaluation.evaluator]: \u001b[0mInference done 4004/4024. 0.0976 s / img. ETA=0:00:01\n",
      "\u001b[32m[06/27 00:04:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:06:37.888756 (0.099002 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/27 00:04:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:06:32 (0.097595 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/27 00:04:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/27 00:04:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/coco_instances_results.json\n",
      "\u001b[32m[06/27 00:04:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.20s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.18s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.048\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.062\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.061\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.042\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.085\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.068\n",
      "\u001b[32m[06/27 00:04:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 4.828 | 11.199 | 3.077  | 3.724 | 6.153 | 5.752 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4024it [00:06, 629.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/27 00:04:15 d2.data.common]: \u001b[0mSerializing 4024 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/27 00:04:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.47 MiB\n",
      "\u001b[32m[06/27 00:04:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 4024 images\n",
      "\u001b[32m[06/27 00:04:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/4024. 0.1147 s / img. ETA=0:07:45\n",
      "\u001b[32m[06/27 00:04:21 d2.evaluation.evaluator]: \u001b[0mInference done 61/4024. 0.1008 s / img. ETA=0:06:45\n",
      "\u001b[32m[06/27 00:04:26 d2.evaluation.evaluator]: \u001b[0mInference done 111/4024. 0.1000 s / img. ETA=0:06:37\n",
      "\u001b[32m[06/27 00:04:31 d2.evaluation.evaluator]: \u001b[0mInference done 162/4024. 0.0996 s / img. ETA=0:06:30\n",
      "\u001b[32m[06/27 00:04:36 d2.evaluation.evaluator]: \u001b[0mInference done 214/4024. 0.0990 s / img. ETA=0:06:22\n",
      "\u001b[32m[06/27 00:04:42 d2.evaluation.evaluator]: \u001b[0mInference done 265/4024. 0.0988 s / img. ETA=0:06:16\n",
      "\u001b[32m[06/27 00:04:47 d2.evaluation.evaluator]: \u001b[0mInference done 315/4024. 0.0988 s / img. ETA=0:06:11\n",
      "\u001b[32m[06/27 00:04:52 d2.evaluation.evaluator]: \u001b[0mInference done 367/4024. 0.0984 s / img. ETA=0:06:04\n",
      "\u001b[32m[06/27 00:04:57 d2.evaluation.evaluator]: \u001b[0mInference done 415/4024. 0.0990 s / img. ETA=0:06:02\n",
      "\u001b[32m[06/27 00:05:02 d2.evaluation.evaluator]: \u001b[0mInference done 466/4024. 0.0987 s / img. ETA=0:05:56\n",
      "\u001b[32m[06/27 00:05:07 d2.evaluation.evaluator]: \u001b[0mInference done 515/4024. 0.0989 s / img. ETA=0:05:52\n",
      "\u001b[32m[06/27 00:05:12 d2.evaluation.evaluator]: \u001b[0mInference done 566/4024. 0.0989 s / img. ETA=0:05:46\n",
      "\u001b[32m[06/27 00:05:17 d2.evaluation.evaluator]: \u001b[0mInference done 618/4024. 0.0987 s / img. ETA=0:05:41\n",
      "\u001b[32m[06/27 00:05:22 d2.evaluation.evaluator]: \u001b[0mInference done 667/4024. 0.0989 s / img. ETA=0:05:36\n",
      "\u001b[32m[06/27 00:05:27 d2.evaluation.evaluator]: \u001b[0mInference done 717/4024. 0.0989 s / img. ETA=0:05:31\n",
      "\u001b[32m[06/27 00:05:32 d2.evaluation.evaluator]: \u001b[0mInference done 766/4024. 0.0990 s / img. ETA=0:05:27\n",
      "\u001b[32m[06/27 00:05:37 d2.evaluation.evaluator]: \u001b[0mInference done 818/4024. 0.0989 s / img. ETA=0:05:21\n",
      "\u001b[32m[06/27 00:05:42 d2.evaluation.evaluator]: \u001b[0mInference done 868/4024. 0.0989 s / img. ETA=0:05:16\n",
      "\u001b[32m[06/27 00:05:47 d2.evaluation.evaluator]: \u001b[0mInference done 919/4024. 0.0988 s / img. ETA=0:05:11\n",
      "\u001b[32m[06/27 00:05:52 d2.evaluation.evaluator]: \u001b[0mInference done 970/4024. 0.0988 s / img. ETA=0:05:05\n",
      "\u001b[32m[06/27 00:05:57 d2.evaluation.evaluator]: \u001b[0mInference done 1021/4024. 0.0988 s / img. ETA=0:05:00\n",
      "\u001b[32m[06/27 00:06:02 d2.evaluation.evaluator]: \u001b[0mInference done 1073/4024. 0.0986 s / img. ETA=0:04:55\n",
      "\u001b[32m[06/27 00:06:07 d2.evaluation.evaluator]: \u001b[0mInference done 1122/4024. 0.0987 s / img. ETA=0:04:50\n",
      "\u001b[32m[06/27 00:06:12 d2.evaluation.evaluator]: \u001b[0mInference done 1173/4024. 0.0986 s / img. ETA=0:04:45\n",
      "\u001b[32m[06/27 00:06:17 d2.evaluation.evaluator]: \u001b[0mInference done 1222/4024. 0.0988 s / img. ETA=0:04:40\n",
      "\u001b[32m[06/27 00:06:23 d2.evaluation.evaluator]: \u001b[0mInference done 1275/4024. 0.0986 s / img. ETA=0:04:35\n",
      "\u001b[32m[06/27 00:06:28 d2.evaluation.evaluator]: \u001b[0mInference done 1326/4024. 0.0986 s / img. ETA=0:04:29\n",
      "\u001b[32m[06/27 00:06:33 d2.evaluation.evaluator]: \u001b[0mInference done 1378/4024. 0.0985 s / img. ETA=0:04:24\n",
      "\u001b[32m[06/27 00:06:38 d2.evaluation.evaluator]: \u001b[0mInference done 1429/4024. 0.0985 s / img. ETA=0:04:19\n",
      "\u001b[32m[06/27 00:06:43 d2.evaluation.evaluator]: \u001b[0mInference done 1479/4024. 0.0985 s / img. ETA=0:04:14\n",
      "\u001b[32m[06/27 00:06:48 d2.evaluation.evaluator]: \u001b[0mInference done 1530/4024. 0.0984 s / img. ETA=0:04:09\n",
      "\u001b[32m[06/27 00:06:53 d2.evaluation.evaluator]: \u001b[0mInference done 1580/4024. 0.0985 s / img. ETA=0:04:04\n",
      "\u001b[32m[06/27 00:06:58 d2.evaluation.evaluator]: \u001b[0mInference done 1632/4024. 0.0984 s / img. ETA=0:03:58\n",
      "\u001b[32m[06/27 00:07:03 d2.evaluation.evaluator]: \u001b[0mInference done 1682/4024. 0.0985 s / img. ETA=0:03:53\n",
      "\u001b[32m[06/27 00:07:08 d2.evaluation.evaluator]: \u001b[0mInference done 1734/4024. 0.0984 s / img. ETA=0:03:48\n",
      "\u001b[32m[06/27 00:07:13 d2.evaluation.evaluator]: \u001b[0mInference done 1785/4024. 0.0984 s / img. ETA=0:03:43\n",
      "\u001b[32m[06/27 00:07:18 d2.evaluation.evaluator]: \u001b[0mInference done 1835/4024. 0.0985 s / img. ETA=0:03:38\n",
      "\u001b[32m[06/27 00:07:23 d2.evaluation.evaluator]: \u001b[0mInference done 1887/4024. 0.0984 s / img. ETA=0:03:33\n",
      "\u001b[32m[06/27 00:07:29 d2.evaluation.evaluator]: \u001b[0mInference done 1939/4024. 0.0984 s / img. ETA=0:03:28\n",
      "\u001b[32m[06/27 00:07:34 d2.evaluation.evaluator]: \u001b[0mInference done 1989/4024. 0.0984 s / img. ETA=0:03:23\n",
      "\u001b[32m[06/27 00:07:39 d2.evaluation.evaluator]: \u001b[0mInference done 2040/4024. 0.0985 s / img. ETA=0:03:18\n",
      "\u001b[32m[06/27 00:07:44 d2.evaluation.evaluator]: \u001b[0mInference done 2093/4024. 0.0984 s / img. ETA=0:03:12\n",
      "\u001b[32m[06/27 00:07:49 d2.evaluation.evaluator]: \u001b[0mInference done 2146/4024. 0.0983 s / img. ETA=0:03:07\n",
      "\u001b[32m[06/27 00:07:54 d2.evaluation.evaluator]: \u001b[0mInference done 2197/4024. 0.0983 s / img. ETA=0:03:02\n",
      "\u001b[32m[06/27 00:07:59 d2.evaluation.evaluator]: \u001b[0mInference done 2246/4024. 0.0983 s / img. ETA=0:02:57\n",
      "\u001b[32m[06/27 00:08:04 d2.evaluation.evaluator]: \u001b[0mInference done 2298/4024. 0.0983 s / img. ETA=0:02:52\n",
      "\u001b[32m[06/27 00:08:09 d2.evaluation.evaluator]: \u001b[0mInference done 2349/4024. 0.0983 s / img. ETA=0:02:46\n",
      "\u001b[32m[06/27 00:08:14 d2.evaluation.evaluator]: \u001b[0mInference done 2398/4024. 0.0984 s / img. ETA=0:02:42\n",
      "\u001b[32m[06/27 00:08:19 d2.evaluation.evaluator]: \u001b[0mInference done 2449/4024. 0.0983 s / img. ETA=0:02:37\n",
      "\u001b[32m[06/27 00:08:24 d2.evaluation.evaluator]: \u001b[0mInference done 2498/4024. 0.0984 s / img. ETA=0:02:32\n",
      "\u001b[32m[06/27 00:08:29 d2.evaluation.evaluator]: \u001b[0mInference done 2550/4024. 0.0984 s / img. ETA=0:02:27\n",
      "\u001b[32m[06/27 00:08:35 d2.evaluation.evaluator]: \u001b[0mInference done 2600/4024. 0.0984 s / img. ETA=0:02:22\n",
      "\u001b[32m[06/27 00:08:40 d2.evaluation.evaluator]: \u001b[0mInference done 2651/4024. 0.0984 s / img. ETA=0:02:17\n",
      "\u001b[32m[06/27 00:08:45 d2.evaluation.evaluator]: \u001b[0mInference done 2700/4024. 0.0984 s / img. ETA=0:02:12\n",
      "\u001b[32m[06/27 00:08:50 d2.evaluation.evaluator]: \u001b[0mInference done 2752/4024. 0.0984 s / img. ETA=0:02:06\n",
      "\u001b[32m[06/27 00:08:55 d2.evaluation.evaluator]: \u001b[0mInference done 2802/4024. 0.0984 s / img. ETA=0:02:01\n",
      "\u001b[32m[06/27 00:09:00 d2.evaluation.evaluator]: \u001b[0mInference done 2853/4024. 0.0984 s / img. ETA=0:01:56\n",
      "\u001b[32m[06/27 00:09:05 d2.evaluation.evaluator]: \u001b[0mInference done 2904/4024. 0.0984 s / img. ETA=0:01:51\n",
      "\u001b[32m[06/27 00:09:10 d2.evaluation.evaluator]: \u001b[0mInference done 2956/4024. 0.0983 s / img. ETA=0:01:46\n",
      "\u001b[32m[06/27 00:09:15 d2.evaluation.evaluator]: \u001b[0mInference done 3006/4024. 0.0984 s / img. ETA=0:01:41\n",
      "\u001b[32m[06/27 00:09:20 d2.evaluation.evaluator]: \u001b[0mInference done 3058/4024. 0.0983 s / img. ETA=0:01:36\n",
      "\u001b[32m[06/27 00:09:25 d2.evaluation.evaluator]: \u001b[0mInference done 3109/4024. 0.0983 s / img. ETA=0:01:31\n",
      "\u001b[32m[06/27 00:09:30 d2.evaluation.evaluator]: \u001b[0mInference done 3158/4024. 0.0984 s / img. ETA=0:01:26\n",
      "\u001b[32m[06/27 00:09:35 d2.evaluation.evaluator]: \u001b[0mInference done 3211/4024. 0.0983 s / img. ETA=0:01:21\n",
      "\u001b[32m[06/27 00:09:40 d2.evaluation.evaluator]: \u001b[0mInference done 3261/4024. 0.0983 s / img. ETA=0:01:16\n",
      "\u001b[32m[06/27 00:09:45 d2.evaluation.evaluator]: \u001b[0mInference done 3313/4024. 0.0983 s / img. ETA=0:01:10\n",
      "\u001b[32m[06/27 00:09:51 d2.evaluation.evaluator]: \u001b[0mInference done 3365/4024. 0.0983 s / img. ETA=0:01:05\n",
      "\u001b[32m[06/27 00:09:56 d2.evaluation.evaluator]: \u001b[0mInference done 3416/4024. 0.0983 s / img. ETA=0:01:00\n",
      "\u001b[32m[06/27 00:10:01 d2.evaluation.evaluator]: \u001b[0mInference done 3466/4024. 0.0983 s / img. ETA=0:00:55\n",
      "\u001b[32m[06/27 00:10:06 d2.evaluation.evaluator]: \u001b[0mInference done 3518/4024. 0.0983 s / img. ETA=0:00:50\n",
      "\u001b[32m[06/27 00:10:11 d2.evaluation.evaluator]: \u001b[0mInference done 3567/4024. 0.0983 s / img. ETA=0:00:45\n",
      "\u001b[32m[06/27 00:10:16 d2.evaluation.evaluator]: \u001b[0mInference done 3618/4024. 0.0983 s / img. ETA=0:00:40\n",
      "\u001b[32m[06/27 00:10:21 d2.evaluation.evaluator]: \u001b[0mInference done 3668/4024. 0.0983 s / img. ETA=0:00:35\n",
      "\u001b[32m[06/27 00:10:26 d2.evaluation.evaluator]: \u001b[0mInference done 3720/4024. 0.0982 s / img. ETA=0:00:30\n",
      "\u001b[32m[06/27 00:10:31 d2.evaluation.evaluator]: \u001b[0mInference done 3772/4024. 0.0982 s / img. ETA=0:00:25\n",
      "\u001b[32m[06/27 00:10:36 d2.evaluation.evaluator]: \u001b[0mInference done 3822/4024. 0.0983 s / img. ETA=0:00:20\n",
      "\u001b[32m[06/27 00:10:41 d2.evaluation.evaluator]: \u001b[0mInference done 3872/4024. 0.0983 s / img. ETA=0:00:15\n",
      "\u001b[32m[06/27 00:10:46 d2.evaluation.evaluator]: \u001b[0mInference done 3922/4024. 0.0983 s / img. ETA=0:00:10\n",
      "\u001b[32m[06/27 00:10:51 d2.evaluation.evaluator]: \u001b[0mInference done 3975/4024. 0.0983 s / img. ETA=0:00:04\n",
      "\u001b[32m[06/27 00:10:56 d2.evaluation.evaluator]: \u001b[0mInference done 4024/4024. 0.0983 s / img. ETA=0:00:00\n",
      "\u001b[32m[06/27 00:10:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:06:40.902349 (0.099752 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/27 00:10:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:06:35 (0.098307 s / img per device, on 1 devices)\n",
      "\u001b[32m[06/27 00:10:56 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[06/27 00:10:56 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/coco_instances_results.json\n",
      "\u001b[32m[06/27 00:10:57 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions ...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.51s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.19s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.069\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.175\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.035\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.053\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.108\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.099\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.100\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.138\n",
      "\u001b[32m[06/27 00:10:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 6.927 | 17.520 | 3.521  | 5.314 | 8.670 | 10.770 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4024it [00:06, 648.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/27 00:11:09 d2.data.common]: \u001b[0mSerializing 4024 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/27 00:11:09 d2.data.common]: \u001b[0mSerialized dataset takes 1.47 MiB\n",
      "\u001b[32m[06/27 00:11:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 4024 images\n",
      "\u001b[32m[06/27 00:11:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/4024. 0.1082 s / img. ETA=0:07:18\n",
      "\u001b[32m[06/27 00:11:16 d2.evaluation.evaluator]: \u001b[0mInference done 62/4024. 0.0985 s / img. ETA=0:06:35\n",
      "\u001b[32m[06/27 00:11:21 d2.evaluation.evaluator]: \u001b[0mInference done 114/4024. 0.0968 s / img. ETA=0:06:24\n",
      "\u001b[32m[06/27 00:11:26 d2.evaluation.evaluator]: \u001b[0mInference done 164/4024. 0.0975 s / img. ETA=0:06:21\n",
      "\u001b[32m[06/27 00:11:31 d2.evaluation.evaluator]: \u001b[0mInference done 214/4024. 0.0982 s / img. ETA=0:06:19\n",
      "\u001b[32m[06/27 00:11:36 d2.evaluation.evaluator]: \u001b[0mInference done 266/4024. 0.0978 s / img. ETA=0:06:12\n",
      "\u001b[32m[06/27 00:11:41 d2.evaluation.evaluator]: \u001b[0mInference done 316/4024. 0.0983 s / img. ETA=0:06:09\n",
      "\u001b[32m[06/27 00:11:46 d2.evaluation.evaluator]: \u001b[0mInference done 368/4024. 0.0980 s / img. ETA=0:06:03\n",
      "\u001b[32m[06/27 00:11:51 d2.evaluation.evaluator]: \u001b[0mInference done 416/4024. 0.0986 s / img. ETA=0:06:00\n",
      "\u001b[32m[06/27 00:11:56 d2.evaluation.evaluator]: \u001b[0mInference done 468/4024. 0.0982 s / img. ETA=0:05:54\n",
      "\u001b[32m[06/27 00:12:01 d2.evaluation.evaluator]: \u001b[0mInference done 517/4024. 0.0985 s / img. ETA=0:05:50\n",
      "\u001b[32m[06/27 00:12:06 d2.evaluation.evaluator]: \u001b[0mInference done 568/4024. 0.0984 s / img. ETA=0:05:44\n",
      "\u001b[32m[06/27 00:12:11 d2.evaluation.evaluator]: \u001b[0mInference done 619/4024. 0.0983 s / img. ETA=0:05:39\n",
      "\u001b[32m[06/27 00:12:16 d2.evaluation.evaluator]: \u001b[0mInference done 670/4024. 0.0984 s / img. ETA=0:05:34\n",
      "\u001b[32m[06/27 00:12:21 d2.evaluation.evaluator]: \u001b[0mInference done 722/4024. 0.0983 s / img. ETA=0:05:29\n",
      "\u001b[32m[06/27 00:12:26 d2.evaluation.evaluator]: \u001b[0mInference done 772/4024. 0.0984 s / img. ETA=0:05:24\n",
      "\u001b[32m[06/27 00:12:32 d2.evaluation.evaluator]: \u001b[0mInference done 823/4024. 0.0984 s / img. ETA=0:05:19\n",
      "\u001b[32m[06/27 00:12:37 d2.evaluation.evaluator]: \u001b[0mInference done 874/4024. 0.0983 s / img. ETA=0:05:13\n",
      "\u001b[32m[06/27 00:12:42 d2.evaluation.evaluator]: \u001b[0mInference done 926/4024. 0.0982 s / img. ETA=0:05:08\n",
      "\u001b[32m[06/27 00:12:47 d2.evaluation.evaluator]: \u001b[0mInference done 978/4024. 0.0981 s / img. ETA=0:05:03\n",
      "\u001b[32m[06/27 00:12:52 d2.evaluation.evaluator]: \u001b[0mInference done 1029/4024. 0.0980 s / img. ETA=0:04:57\n",
      "\u001b[32m[06/27 00:12:57 d2.evaluation.evaluator]: \u001b[0mInference done 1080/4024. 0.0980 s / img. ETA=0:04:52\n",
      "\u001b[32m[06/27 00:13:02 d2.evaluation.evaluator]: \u001b[0mInference done 1130/4024. 0.0980 s / img. ETA=0:04:47\n",
      "\u001b[32m[06/27 00:13:07 d2.evaluation.evaluator]: \u001b[0mInference done 1181/4024. 0.0980 s / img. ETA=0:04:42\n",
      "\u001b[32m[06/27 00:13:12 d2.evaluation.evaluator]: \u001b[0mInference done 1231/4024. 0.0981 s / img. ETA=0:04:37\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset, LVISEvaluator\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluation_list = []\n",
    "for model in model_list:\n",
    "    cfg.MODEL.WEIGHTS = model\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "    cfg.DATASETS.TEST = (\"pedestrain_test\", )\n",
    "    \n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    COCOEvaluator.reset\n",
    "    evaluator = COCOEvaluator(\"pedestrain_test\", cfg, False, output_dir = cfg.OUTPUT_DIR)\n",
    "\n",
    "    val_loader = build_detection_test_loader(cfg, \"pedestrain_test\")\n",
    "    evaluation_list.append(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('bbox', {'AP': nan, 'AP50': nan, 'AP75': nan, 'APs': nan, 'APm': nan, 'APl': nan})]), OrderedDict([('bbox', {'AP': 0.7920792079207918, 'AP50': 0.99009900990099, 'AP75': 0.99009900990099, 'APs': 0.7920792079207921, 'APm': 0.34653465346534656, 'APl': 0.0})]), OrderedDict([('bbox', {'AP': 0.8779719454349669, 'AP50': 1.6733252272595676, 'AP75': 0.99009900990099, 'APs': 0.8221499860829456, 'APm': 0.5514302970605705, 'APl': 1.7633191890617632})]), OrderedDict([('bbox', {'AP': 1.416113126198241, 'AP50': 4.146725692836759, 'AP75': 0.6430614033827186, 'APs': 1.2114060485487679, 'APm': 1.7479566807726332, 'APl': 1.782178217821782})]), OrderedDict([('bbox', {'AP': 1.474629156784471, 'AP50': 3.2071177114215255, 'AP75': 1.0274241709885275, 'APs': 1.5072754636384733, 'APm': 1.448637476076259, 'APl': 3.4396436074407877})]), OrderedDict([('bbox', {'AP': 2.7799631686706405, 'AP50': 8.201902180650603, 'AP75': 0.7229870296220217, 'APs': 2.4302054392025396, 'APm': 3.664571185313021, 'APl': 2.9190867373744487})]), OrderedDict([('bbox', {'AP': 4.365055883599328, 'AP50': 9.786785372846046, 'AP75': 3.106098254654977, 'APs': 3.6748144383109644, 'APm': 5.131471695646903, 'APl': 4.113893004684306})]), OrderedDict([('bbox', {'AP': 5.072990736152868, 'AP50': 13.343960656447118, 'AP75': 2.1192576348315426, 'APs': 3.704140040844627, 'APm': 6.6967432582531075, 'APl': 7.707224116972154})]), OrderedDict([('bbox', {'AP': 4.828097950619085, 'AP50': 11.199326388908995, 'AP75': 3.0770600856837387, 'APs': 3.724394555586799, 'APm': 6.152585832673994, 'APl': 5.752116554669624})]), OrderedDict([('bbox', {'AP': 6.92666897005893, 'AP50': 17.520453408621567, 'AP75': 3.520791452304158, 'APs': 5.314299315507101, 'APm': 8.669620587628714, 'APl': 10.769885647887474})]), OrderedDict([('bbox', {'AP': 6.936715654165922, 'AP50': 15.215907245297908, 'AP75': 4.282530776863893, 'APs': 4.99023635582738, 'APm': 8.937107971018015, 'APl': 9.641018215747003})]), OrderedDict([('bbox', {'AP': 9.44526238966597, 'AP50': 22.392663675445323, 'AP75': 5.738371166807103, 'APs': 6.508431200874189, 'APm': 12.57486614790376, 'APl': 15.397469320973952})]), OrderedDict([('bbox', {'AP': 10.8450859504076, 'AP50': 24.205125620181565, 'AP75': 7.145339203944914, 'APs': 7.994627176372333, 'APm': 13.95590938430199, 'APl': 16.42316806685397})]), OrderedDict([('bbox', {'AP': 11.620194694807868, 'AP50': 25.919546880149507, 'AP75': 8.044468842420683, 'APs': 8.985816117106824, 'APm': 14.6379604992589, 'APl': 16.51566185988879})]), OrderedDict([('bbox', {'AP': 11.789532057145058, 'AP50': 25.61236381027697, 'AP75': 8.326540806603658, 'APs': 8.825760648543813, 'APm': 14.929301472848353, 'APl': 17.683229298251877})]), OrderedDict([('bbox', {'AP': 12.419960184142699, 'AP50': 26.45834075588207, 'AP75': 9.377322643314955, 'APs': 9.701303960662012, 'APm': 15.356026981547513, 'APl': 20.261363501453637})]), OrderedDict([('bbox', {'AP': 12.346690430765559, 'AP50': 26.48569486033493, 'AP75': 8.808488932347833, 'APs': 9.296547184963565, 'APm': 15.49998671194151, 'APl': 19.687339417297608})]), OrderedDict([('bbox', {'AP': 12.070976885637704, 'AP50': 25.861515444289136, 'AP75': 8.79011577799773, 'APs': 9.082830943728254, 'APm': 15.438592128163348, 'APl': 19.861596278715147})]), OrderedDict([('bbox', {'AP': 12.450554933323415, 'AP50': 26.537376667747825, 'AP75': 9.335981695747634, 'APs': 9.50626196156194, 'APm': 15.72913388232126, 'APl': 20.094123223608126})]), OrderedDict([('bbox', {'AP': 12.46166899796417, 'AP50': 27.252989977887882, 'AP75': 8.948804222487313, 'APs': 9.307251542205371, 'APm': 15.814608211584893, 'APl': 19.970543070123988})]), OrderedDict([('bbox', {'AP': 12.460662114153836, 'AP50': 26.589247068651627, 'AP75': 9.297509444911684, 'APs': 9.442260123689392, 'APm': 15.812718584521642, 'APl': 19.521140753335967})]), OrderedDict([('bbox', {'AP': 12.430281003807856, 'AP50': 27.30154713921804, 'AP75': 9.205729946679178, 'APs': 9.426795060677598, 'APm': 15.641489754406368, 'APl': 19.019787414098925})]), OrderedDict([('bbox', {'AP': 12.451646476443024, 'AP50': 26.65552118976633, 'AP75': 9.265747690547842, 'APs': 9.403089944627991, 'APm': 15.760209592326929, 'APl': 19.944049421485584})]), OrderedDict([('bbox', {'AP': 12.47894003968933, 'AP50': 27.319811444175347, 'AP75': 9.362917445025158, 'APs': 9.474870853038956, 'APm': 15.731962054520416, 'APl': 19.810463748655565})]), OrderedDict([('bbox', {'AP': 12.740091853089067, 'AP50': 27.42434259163949, 'AP75': 9.34138490868803, 'APs': 9.666382180971317, 'APm': 16.055061037451644, 'APl': 19.79526734335076})])]\n"
     ]
    }
   ],
   "source": [
    "print(evaluation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 0.7920792079207918, 0.8779719454349669, 1.416113126198241, 1.474629156784471, 2.7799631686706405, 4.365055883599328, 5.072990736152868, 4.828097950619085, 6.92666897005893, 6.936715654165922, 9.44526238966597, 10.8450859504076, 11.620194694807868, 11.789532057145058, 12.419960184142699, 12.346690430765559, 12.070976885637704, 12.450554933323415, 12.46166899796417, 12.460662114153836, 12.430281003807856, 12.451646476443024, 12.47894003968933, 12.740091853089067]\n",
      "[nan, 0.7920792079207921, 0.8221499860829456, 1.2114060485487679, 1.5072754636384733, 2.4302054392025396, 3.6748144383109644, 3.704140040844627, 3.724394555586799, 5.314299315507101, 4.99023635582738, 6.508431200874189, 7.994627176372333, 8.985816117106824, 8.825760648543813, 9.701303960662012, 9.296547184963565, 9.082830943728254, 9.50626196156194, 9.307251542205371, 9.442260123689392, 9.426795060677598, 9.403089944627991, 9.474870853038956, 9.666382180971317]\n",
      "[nan, 0.34653465346534656, 0.5514302970605705, 1.7479566807726332, 1.448637476076259, 3.664571185313021, 5.131471695646903, 6.6967432582531075, 6.152585832673994, 8.669620587628714, 8.937107971018015, 12.57486614790376, 13.95590938430199, 14.6379604992589, 14.929301472848353, 15.356026981547513, 15.49998671194151, 15.438592128163348, 15.72913388232126, 15.814608211584893, 15.812718584521642, 15.641489754406368, 15.760209592326929, 15.731962054520416, 16.055061037451644]\n",
      "[nan, 0.0, 1.7633191890617632, 1.782178217821782, 3.4396436074407877, 2.9190867373744487, 4.113893004684306, 7.707224116972154, 5.752116554669624, 10.769885647887474, 9.641018215747003, 15.397469320973952, 16.42316806685397, 16.51566185988879, 17.683229298251877, 20.261363501453637, 19.687339417297608, 19.861596278715147, 20.094123223608126, 19.970543070123988, 19.521140753335967, 19.019787414098925, 19.944049421485584, 19.810463748655565, 19.79526734335076]\n",
      "[5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000, 55000, 60000, 65000, 70000, 75000, 80000, 85000, 90000, 95000, 100000, 105000, 110000, 115000, 120000, 126000]\n"
     ]
    }
   ],
   "source": [
    "iter_count = 0\n",
    "baseline_x_AP, baseline_x_APs, baseline_x_APm, baseline_x_APl = [], [], [], []\n",
    "baseline_y = []\n",
    "for evaluation in evaluation_list[:-1]:\n",
    "#     print(evaluation['bbox']['AP'])\n",
    "    baseline_x_AP.append(evaluation['bbox']['AP'])\n",
    "    baseline_x_APs.append(evaluation['bbox']['APs'])\n",
    "    baseline_x_APm.append(evaluation['bbox']['APm'])\n",
    "    baseline_x_APl.append(evaluation['bbox']['APl'])\n",
    "    iter_count+=5000\n",
    "    baseline_y.append(iter_count)\n",
    "baseline_x_AP.append(evaluation_list[-1]['bbox']['AP'])\n",
    "baseline_x_APs.append(evaluation_list[-1]['bbox']['APs'])\n",
    "baseline_x_APm.append(evaluation_list[-1]['bbox']['APm'])\n",
    "baseline_x_APl.append(evaluation_list[-1]['bbox']['APl'])\n",
    "baseline_y.append(126000)\n",
    "print(baseline_x_AP)\n",
    "print(baseline_x_APs)\n",
    "print(baseline_x_APm)\n",
    "print(baseline_x_APl)\n",
    "print(baseline_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evaluation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4024it [00:06, 606.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[06/26 23:12:35 d2.data.common]: \u001b[0mSerializing 4024 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[06/26 23:12:35 d2.data.common]: \u001b[0mSerialized dataset takes 1.47 MiB\n",
      "\u001b[32m[06/26 23:12:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 4024 images\n",
      "\u001b[32m[06/26 23:12:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/4024. 0.0402 s / img. ETA=0:02:46\n",
      "\u001b[32m[06/26 23:12:41 d2.evaluation.evaluator]: \u001b[0mInference done 134/4024. 0.0395 s / img. ETA=0:02:38\n",
      "\u001b[32m[06/26 23:12:46 d2.evaluation.evaluator]: \u001b[0mInference done 257/4024. 0.0394 s / img. ETA=0:02:33\n",
      "\u001b[32m[06/26 23:12:51 d2.evaluation.evaluator]: \u001b[0mInference done 380/4024. 0.0394 s / img. ETA=0:02:28\n",
      "\u001b[32m[06/26 23:12:56 d2.evaluation.evaluator]: \u001b[0mInference done 503/4024. 0.0394 s / img. ETA=0:02:23\n",
      "\u001b[32m[06/26 23:13:01 d2.evaluation.evaluator]: \u001b[0mInference done 626/4024. 0.0394 s / img. ETA=0:02:18\n",
      "\u001b[32m[06/26 23:13:06 d2.evaluation.evaluator]: \u001b[0mInference done 748/4024. 0.0394 s / img. ETA=0:02:13\n",
      "\u001b[32m[06/26 23:13:11 d2.evaluation.evaluator]: \u001b[0mInference done 871/4024. 0.0394 s / img. ETA=0:02:08\n",
      "\u001b[32m[06/26 23:13:16 d2.evaluation.evaluator]: \u001b[0mInference done 994/4024. 0.0394 s / img. ETA=0:02:03\n",
      "\u001b[32m[06/26 23:13:21 d2.evaluation.evaluator]: \u001b[0mInference done 1116/4024. 0.0395 s / img. ETA=0:01:58\n",
      "\u001b[32m[06/26 23:13:26 d2.evaluation.evaluator]: \u001b[0mInference done 1239/4024. 0.0394 s / img. ETA=0:01:53\n",
      "\u001b[32m[06/26 23:13:31 d2.evaluation.evaluator]: \u001b[0mInference done 1362/4024. 0.0394 s / img. ETA=0:01:48\n",
      "\u001b[32m[06/26 23:13:36 d2.evaluation.evaluator]: \u001b[0mInference done 1485/4024. 0.0394 s / img. ETA=0:01:43\n",
      "\u001b[32m[06/26 23:13:41 d2.evaluation.evaluator]: \u001b[0mInference done 1608/4024. 0.0394 s / img. ETA=0:01:38\n",
      "\u001b[32m[06/26 23:13:46 d2.evaluation.evaluator]: \u001b[0mInference done 1732/4024. 0.0394 s / img. ETA=0:01:33\n",
      "\u001b[32m[06/26 23:13:51 d2.evaluation.evaluator]: \u001b[0mInference done 1855/4024. 0.0394 s / img. ETA=0:01:28\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-e6a279d22834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_detection_test_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pedestrain_test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0minference_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/detectron2/evaluation/evaluator.py\u001b[0m in \u001b[0;36minference_on_dataset\u001b[0;34m(model, data_loader, evaluator)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mstart_compute_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/detectron2/modeling/meta_arch/rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/detectron2/modeling/meta_arch/rcnn.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, batched_inputs, detected_instances, do_postprocess)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdetected_instances\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproposal_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproposal_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0;34m\"proposals\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatched_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/detectron2/modeling/proposal_generator/rpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_nms_topk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_box_side_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             )\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/detectron2/modeling/proposal_generator/rpn_outputs.py\u001b[0m in \u001b[0;36mfind_top_rpn_proposals\u001b[0;34m(proposals, pred_objectness_logits, images, nms_thresh, pre_nms_topk, post_nms_topk, min_box_side_len, training)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# sort is faster than topk (https://github.com/pytorch/pytorch/issues/22812)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# topk_scores_i, topk_idx = logits_i.topk(num_proposals_i, dim=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mlogits_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mtopk_scores_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnum_proposals_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mtopk_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnum_proposals_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset, LVISEvaluator\n",
    "from detectron2.data import build_detection_test_loader\n",
    "cfg.MODEL.WEIGHTS = '/root/notebooks/Module_final/detectron2_output/baseline_FPN_final_v2/model_final.pth'\n",
    "predictor = DefaultPredictor(cfg)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"pedestrain_test\", )\n",
    "predictor = DefaultPredictor(cfg)\n",
    "# COCOEvaluator.reset\n",
    "evaluator = COCOEvaluator(\"pedestrain_test\", cfg, False, output_dir = cfg.OUTPUT_DIR)\n",
    "\n",
    "val_loader = build_detection_test_loader(cfg, \"pedestrain_test\")\n",
    "inference_on_dataset(predictor.model, val_loader, evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
