{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from models import CompletionNetwork, ContextDiscriminator\n",
    "from datasets import ImageDataset\n",
    "from losses import completion_network_loss\n",
    "from utils import (\n",
    "    gen_input_mask,\n",
    "    gen_hole_area,\n",
    "    crop,\n",
    "    sample_random_batch,\n",
    "    poisson_blend,\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adadelta, Adam\n",
    "from torch.nn import BCELoss, DataParallel\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/notebooks/Module_final/pedestrian_generator\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/root/notebooks/Module_final/gandata1\"\n",
    "out_path = \"/root/notebooks/Module_final/result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-f'], dest='f', nargs=None, const=None, default=None, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_dir', type=str, default=data_path)\n",
    "parser.add_argument('--result_dir', type=str, default=out_path)\n",
    "parser.add_argument('--recursive_search', action='store_true', default=False)\n",
    "parser.add_argument('--init_model_cn', type=str, default=None)\n",
    "parser.add_argument('--init_model_cd', type=str, default=None)\n",
    "parser.add_argument('--steps_1', type=int, default=100)\n",
    "parser.add_argument('--steps_2', type=int, default=100)\n",
    "parser.add_argument('--steps_3', type=int, default=100)\n",
    "parser.add_argument('--snaperiod_1', type=int, default=10000)\n",
    "parser.add_argument('--snaperiod_2', type=int, default=2000)\n",
    "parser.add_argument('--snaperiod_3', type=int, default=10000)\n",
    "parser.add_argument('--max_holes', type=int, default=1)\n",
    "parser.add_argument('--hole_min_w', type=int, default=48)\n",
    "parser.add_argument('--hole_max_w', type=int, default=96)\n",
    "parser.add_argument('--hole_min_h', type=int, default=48)\n",
    "parser.add_argument('--hole_max_h', type=int, default=96)\n",
    "parser.add_argument('--cn_input_size', type=int, default=160)\n",
    "parser.add_argument('--ld_input_size', type=int, default=96)\n",
    "parser.add_argument('--optimizer', type=str, choices=['adadelta', 'adam'], default='adadelta')\n",
    "parser.add_argument('--bsize', type=int, default=16)\n",
    "parser.add_argument('--bdivs', type=int, default=1)\n",
    "parser.add_argument('--data_parallel', action='store_true')\n",
    "parser.add_argument('--num_test_completions', type=int, default=16)\n",
    "parser.add_argument('--mpv', nargs=3, type=float, default=None)\n",
    "parser.add_argument('--alpha', type=float, default=4e-4)\n",
    "parser.add_argument('--arc', type=str, choices=['celeba', 'places2'], default='celeba')\n",
    "\n",
    "parser.add_argument('-f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Preparation\n",
    "# ================================================\n",
    "args.data_dir = os.path.expanduser(args.data_dir)\n",
    "args.result_dir = os.path.expanduser(args.result_dir)\n",
    "if args.init_model_cn != None:\n",
    "    args.init_model_cn = os.path.expanduser(args.init_model_cn)\n",
    "if args.init_model_cd != None:\n",
    "    args.init_model_cd = os.path.expanduser(args.init_model_cd)\n",
    "if torch.cuda.is_available() == False:\n",
    "    raise Exception('At least one gpu must be available.')\n",
    "else:\n",
    "    gpu = torch.device('cuda:0')\n",
    "\n",
    "# create result directory (if necessary)\n",
    "if os.path.exists(args.result_dir) == False:\n",
    "    os.makedirs(args.result_dir)\n",
    "\n",
    "    \n",
    "#code below not used    \n",
    "for s in ['phase_1', 'phase_2', 'phase_3']:\n",
    "    if os.path.exists(os.path.join(args.result_dir, s)) == False:\n",
    "        os.makedirs(os.path.join(args.result_dir, s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "trnsfm = transforms.Compose([\n",
    "    #transforms.Resize(args.cn_input_size),\n",
    "    #transforms.RandomCrop((args.cn_input_size, args.cn_input_size)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "test_dset = ImageDataset(args.data_dir, trnsfm, recursive_search=args.recursive_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dset.__getitem__(1000)[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dset.__getitem__(1000)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset... (it may take a few minutes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "computing mean pixel value for training dataset...: 100%|██████████| 5000/5000 [00:37<00:00, 133.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# dataset\n",
    "trnsfm = transforms.Compose([\n",
    "    #transforms.Resize(args.cn_input_size),\n",
    "    #transforms.RandomCrop((args.cn_input_size, args.cn_input_size)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "print('loading dataset... (it may take a few minutes)')\n",
    "train_dset = ImageDataset(args.data_dir, trnsfm, recursive_search=args.recursive_search)\n",
    "test_dset = ImageDataset(args.data_dir, trnsfm, recursive_search=args.recursive_search)\n",
    "train_loader = DataLoader(train_dset, batch_size=(args.bsize // args.bdivs), shuffle=True)\n",
    "\n",
    "# compute mean pixel value of training dataset\n",
    "mpv = np.zeros(shape=(3,))\n",
    "if args.mpv == None:\n",
    "    pbar = tqdm(total=len(train_dset.street_imgpaths), desc='computing mean pixel value for training dataset...')\n",
    "    for imgpath in train_dset.street_imgpaths:\n",
    "        img = Image.open(imgpath)\n",
    "        x = np.array(img, dtype=np.float32) / 255.\n",
    "        mpv += x.mean(axis=(0,1))\n",
    "        pbar.update()\n",
    "    mpv /= len(train_dset.street_imgpaths)\n",
    "    pbar.close()\n",
    "else:\n",
    "    mpv = np.array(args.mpv)\n",
    "\n",
    "# save training config\n",
    "mpv_json = []\n",
    "for i in range(3):\n",
    "    mpv_json.append(float(mpv[i])) # convert to json serializable type\n",
    "args_dict = vars(args)\n",
    "args_dict['mpv'] = mpv_json\n",
    "with open(os.path.join(args.result_dir, 'config.json'), mode='w') as f:\n",
    "    json.dump(args_dict, f)\n",
    "\n",
    "# make mpv & alpha tensor\n",
    "mpv = torch.tensor(mpv.astype(np.float32).reshape(1, 3, 1, 1)).to(gpu)\n",
    "alpha = torch.tensor(args.alpha).to(gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-95f2dcbc6839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# mask = gen_input_mask(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m#     shape=(x.shape[0], 3, x.shape[2], x.shape[3]),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "    # ================================================\n",
    "    # Training Phase 1\n",
    "    # ================================================\n",
    "    model_cn = CompletionNetwork()\n",
    "    if args.data_parallel:\n",
    "        model_cn = DataParallel(model_cn)\n",
    "    if args.init_model_cn != None:\n",
    "        model_cn.load_state_dict(torch.load(args.init_model_cn, map_location='cpu'))\n",
    "    if args.optimizer == 'adadelta':\n",
    "        opt_cn = Adadelta(model_cn.parameters())\n",
    "    else:\n",
    "        opt_cn = Adam(model_cn.parameters())\n",
    "    model_cn = model_cn.to(gpu)\n",
    "\n",
    "    # training\n",
    "    cnt_bdivs = 0\n",
    "    pbar = tqdm(total=args.steps_1)\n",
    "    while pbar.n < args.steps_1:\n",
    "        for street_img, mask_with_poeple in train_loader:\n",
    "            street_img = street_img.to(gpu)\n",
    "            mask_with_poeple = mask_with_poeple.to(gpu)\n",
    "            # forward\n",
    "            #x = x.to(gpu)\n",
    "            # mask = gen_input_mask(\n",
    "            #     shape=(x.shape[0], 3, x.shape[2], x.shape[3]),\n",
    "            #     position = \n",
    "            #     w_h = ).to(gpu)\n",
    "            # x_mask = x - x * mask + mpv * mask\n",
    "            input = torch.cat((x_mask, mask), dim=1)\n",
    "            output = model_cn(input)\n",
    "            loss = completion_network_loss(x, output, mask)\n",
    "\n",
    "            # backward\n",
    "            loss.backward()\n",
    "            cnt_bdivs += 1\n",
    "\n",
    "            if cnt_bdivs >= args.bdivs:\n",
    "                cnt_bdivs = 0\n",
    "                # optimize\n",
    "                opt_cn.step()\n",
    "                # clear grads\n",
    "                opt_cn.zero_grad()\n",
    "                # update progbar\n",
    "                pbar.set_description('phase 1 | train loss: %.5f' % loss.cpu())\n",
    "                pbar.update()\n",
    "                # test\n",
    "                if pbar.n % args.snaperiod_1 == 0:\n",
    "                    with torch.no_grad():\n",
    "                        x = sample_random_batch(test_dset, batch_size=args.num_test_completions).to(gpu)\n",
    "                        mask = gen_input_mask(\n",
    "                            shape=(x.shape[0], 1, x.shape[2], x.shape[3]),\n",
    "                            hole_size=((args.hole_min_w, args.hole_max_w), (args.hole_min_h, args.hole_max_h)),\n",
    "                            hole_area=gen_hole_area((args.ld_input_size, args.ld_input_size), (x.shape[3], x.shape[2])),\n",
    "                            max_holes=args.max_holes,\n",
    "                        ).to(gpu)\n",
    "                        x_mask = x - x * mask + mpv * mask\n",
    "                        input = torch.cat((x_mask, mask), dim=1)\n",
    "                        output = model_cn(input)\n",
    "                        completed = poisson_blend(x, output, mask)\n",
    "                        imgs = torch.cat((x.cpu(), x_mask.cpu(), completed.cpu()), dim=0)\n",
    "                        imgpath = os.path.join(args.result_dir, 'phase_1', 'step%d.png' % pbar.n)\n",
    "                        model_cn_path = os.path.join(args.result_dir, 'phase_1', 'model_cn_step%d' % pbar.n)\n",
    "                        save_image(imgs, imgpath, nrow=len(x))\n",
    "                        if args.data_parallel:\n",
    "                            torch.save(model_cn.module.state_dict(), model_cn_path)\n",
    "                        else:\n",
    "                            torch.save(model_cn.state_dict(), model_cn_path)\n",
    "                # terminate\n",
    "                if pbar.n >= args.steps_1:\n",
    "                    break\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Training Phase 2\n",
    "# ================================================\n",
    "model_cd = ContextDiscriminator(\n",
    "    local_input_shape=(3, args.ld_input_size, args.ld_input_size),\n",
    "    global_input_shape=(3, args.cn_input_size, args.cn_input_size),\n",
    "    arc=args.arc,\n",
    ")\n",
    "if args.data_parallel:\n",
    "    model_cd = DataParallel(model_cd)\n",
    "if args.init_model_cd != None:\n",
    "    model_cd.load_state_dict(torch.load(args.init_model_cd, map_location='cpu'))\n",
    "if args.optimizer == 'adadelta':\n",
    "    opt_cd = Adadelta(model_cd.parameters())\n",
    "else:\n",
    "    opt_cd = Adam(model_cd.parameters())\n",
    "model_cd = model_cd.to(gpu)\n",
    "bceloss = BCELoss()\n",
    "\n",
    "# training\n",
    "cnt_bdivs = 0\n",
    "pbar = tqdm(total=args.steps_2)\n",
    "while pbar.n < args.steps_2:\n",
    "    for x in train_loader:\n",
    "\n",
    "        # fake forward\n",
    "        x = x.to(gpu)\n",
    "        hole_area_fake = gen_hole_area((args.ld_input_size, args.ld_input_size), (x.shape[3], x.shape[2]))\n",
    "        mask = gen_input_mask(\n",
    "            shape=(x.shape[0], 1, x.shape[2], x.shape[3]),\n",
    "            hole_size=((args.hole_min_w, args.hole_max_w), (args.hole_min_h, args.hole_max_h)),\n",
    "            hole_area=hole_area_fake,\n",
    "            max_holes=args.max_holes,\n",
    "        ).to(gpu)\n",
    "        fake = torch.zeros((len(x), 1)).to(gpu)\n",
    "        x_mask = x - x * mask + mpv * mask\n",
    "        input_cn = torch.cat((x_mask, mask), dim=1)\n",
    "        output_cn = model_cn(input_cn)\n",
    "        input_gd_fake = output_cn.detach()\n",
    "        input_ld_fake = crop(input_gd_fake, hole_area_fake)\n",
    "        output_fake = model_cd((input_ld_fake.to(gpu), input_gd_fake.to(gpu)))\n",
    "        loss_fake = bceloss(output_fake, fake)\n",
    "\n",
    "        # real forward\n",
    "        hole_area_real = gen_hole_area(size=(args.ld_input_size, args.ld_input_size), mask_size=(x.shape[3], x.shape[2]))\n",
    "        real = torch.ones((len(x), 1)).to(gpu)\n",
    "        input_gd_real = x\n",
    "        input_ld_real = crop(input_gd_real, hole_area_real)\n",
    "        output_real = model_cd((input_ld_real, input_gd_real))\n",
    "        loss_real = bceloss(output_real, real)\n",
    "\n",
    "        # reduce\n",
    "        loss = (loss_fake + loss_real) / 2.\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        cnt_bdivs += 1\n",
    "\n",
    "        if cnt_bdivs >= args.bdivs:\n",
    "            cnt_bdivs = 0\n",
    "            # optimize\n",
    "            opt_cd.step()\n",
    "            # clear grads\n",
    "            opt_cd.zero_grad()\n",
    "            # update progbar\n",
    "            pbar.set_description('phase 2 | train loss: %.5f' % loss.cpu())\n",
    "            pbar.update()\n",
    "            # test\n",
    "            if pbar.n % args.snaperiod_2 == 0:\n",
    "                with torch.no_grad():\n",
    "                    x = sample_random_batch(test_dset, batch_size=args.num_test_completions).to(gpu)\n",
    "                    mask = gen_input_mask(\n",
    "                        shape=(x.shape[0], 1, x.shape[2], x.shape[3]),\n",
    "                        hole_size=((args.hole_min_w, args.hole_max_w), (args.hole_min_h, args.hole_max_h)),\n",
    "                        hole_area=gen_hole_area((args.ld_input_size, args.ld_input_size), (x.shape[3], x.shape[2])),\n",
    "                        max_holes=args.max_holes,\n",
    "                    ).to(gpu)\n",
    "                    x_mask = x - x * mask + mpv * mask\n",
    "                    input = torch.cat((x_mask, mask), dim=1)\n",
    "                    output = model_cn(input)\n",
    "                    completed = poisson_blend(x, output, mask)\n",
    "                    imgs = torch.cat((x.cpu(), x_mask.cpu(), completed.cpu()), dim=0)\n",
    "                    imgpath = os.path.join(args.result_dir, 'phase_2', 'step%d.png' % pbar.n)\n",
    "                    model_cd_path = os.path.join(args.result_dir, 'phase_2', 'model_cd_step%d' % pbar.n)\n",
    "                    save_image(imgs, imgpath, nrow=len(x))\n",
    "                    if args.data_parallel:\n",
    "                        torch.save(model_cd.module.state_dict(), model_cd_path)\n",
    "                    else:\n",
    "                        torch.save(model_cd.state_dict(), model_cd_path)\n",
    "            # terminate\n",
    "            if pbar.n >= args.steps_2:\n",
    "                break\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Training Phase 3\n",
    "# ================================================\n",
    "# training\n",
    "cnt_bdivs = 0\n",
    "pbar = tqdm(total=args.steps_3)\n",
    "while pbar.n < args.steps_3:\n",
    "    for x in train_loader:\n",
    "\n",
    "        # forward model_cd\n",
    "        x = x.to(gpu)\n",
    "        hole_area_fake = gen_hole_area((args.ld_input_size, args.ld_input_size), (x.shape[3], x.shape[2]))\n",
    "        mask = gen_input_mask(\n",
    "            shape=(x.shape[0], 1, x.shape[2], x.shape[3]),\n",
    "            hole_size=((args.hole_min_w, args.hole_max_w), (args.hole_min_h, args.hole_max_h)),\n",
    "            hole_area=hole_area_fake,\n",
    "            max_holes=args.max_holes,\n",
    "        ).to(gpu)\n",
    "\n",
    "        # fake forward\n",
    "        fake = torch.zeros((len(x), 1)).to(gpu)\n",
    "        x_mask = x - x * mask + mpv * mask\n",
    "        input_cn = torch.cat((x_mask, mask), dim=1)\n",
    "        output_cn = model_cn(input_cn)\n",
    "        input_gd_fake = output_cn.detach()\n",
    "        input_ld_fake = crop(input_gd_fake, hole_area_fake)\n",
    "        output_fake = model_cd((input_ld_fake, input_gd_fake))\n",
    "        loss_cd_fake = bceloss(output_fake, fake)\n",
    "\n",
    "        # real forward\n",
    "        hole_area_real = gen_hole_area(size=(args.ld_input_size, args.ld_input_size), mask_size=(x.shape[3], x.shape[2]))\n",
    "        real = torch.ones((len(x), 1)).to(gpu)\n",
    "        input_gd_real = x\n",
    "        input_ld_real = crop(input_gd_real, hole_area_real)\n",
    "        output_real = model_cd((input_ld_real, input_gd_real))\n",
    "        loss_cd_real = bceloss(output_real, real)\n",
    "\n",
    "        # reduce\n",
    "        loss_cd = (loss_cd_fake + loss_cd_real) * alpha / 2.\n",
    "\n",
    "        # backward model_cd\n",
    "        loss_cd.backward()\n",
    "\n",
    "        cnt_bdivs += 1\n",
    "        if cnt_bdivs >= args.bdivs:\n",
    "            # optimize\n",
    "            opt_cd.step()\n",
    "            # clear grads\n",
    "            opt_cd.zero_grad()\n",
    "\n",
    "        # forward model_cn\n",
    "        loss_cn_1 = completion_network_loss(x, output_cn, mask)\n",
    "        input_gd_fake = output_cn\n",
    "        input_ld_fake = crop(input_gd_fake, hole_area_fake)\n",
    "        output_fake = model_cd((input_ld_fake, (input_gd_fake)))\n",
    "        loss_cn_2 = bceloss(output_fake, real)\n",
    "\n",
    "        # reduce\n",
    "        loss_cn = (loss_cn_1 + alpha * loss_cn_2) / 2.\n",
    "\n",
    "        # backward model_cn\n",
    "        loss_cn.backward()\n",
    "\n",
    "        if cnt_bdivs >= args.bdivs:\n",
    "            cnt_bdivs = 0\n",
    "            # optimize\n",
    "            opt_cn.step()\n",
    "            # clear grads\n",
    "            opt_cn.zero_grad()\n",
    "            # update progbar\n",
    "            pbar.set_description('phase 3 | train loss (cd): %.5f (cn): %.5f' % (loss_cd.cpu(), loss_cn.cpu()))\n",
    "            pbar.update()\n",
    "            # test\n",
    "            if pbar.n % args.snaperiod_3 == 0:\n",
    "                with torch.no_grad():\n",
    "                    x = sample_random_batch(test_dset, batch_size=args.num_test_completions).to(gpu)\n",
    "                    mask = gen_input_mask(\n",
    "                        shape=(x.shape[0], 1, x.shape[2], x.shape[3]),\n",
    "                        hole_size=((args.hole_min_w, args.hole_max_w), (args.hole_min_h, args.hole_max_h)),\n",
    "                        hole_area=gen_hole_area((args.ld_input_size, args.ld_input_size), (x.shape[3], x.shape[2])),\n",
    "                        max_holes=args.max_holes,\n",
    "                    ).to(gpu)\n",
    "                    x_mask = x - x * mask + mpv * mask\n",
    "                    input = torch.cat((x_mask, mask), dim=1)\n",
    "                    output = model_cn(input)\n",
    "                    completed = poisson_blend(x, output, mask)\n",
    "                    imgs = torch.cat((x.cpu(), x_mask.cpu(), completed.cpu()), dim=0)\n",
    "                    imgpath = os.path.join(args.result_dir, 'phase_3', 'step%d.png' % pbar.n)\n",
    "                    model_cn_path = os.path.join(args.result_dir, 'phase_3', 'model_cn_step%d' % pbar.n)\n",
    "                    model_cd_path = os.path.join(args.result_dir, 'phase_3', 'model_cd_step%d' % pbar.n)\n",
    "                    save_image(imgs, imgpath, nrow=len(x))\n",
    "                    if args.data_parallel:\n",
    "                        torch.save(model_cn.module.state_dict(), model_cn_path)\n",
    "                        torch.save(model_cd.module.state_dict(), model_cd_path)\n",
    "                    else:\n",
    "                        torch.save(model_cn.state_dict(), model_cn_path)\n",
    "                        torch.save(model_cd.state_dict(), model_cd_path)\n",
    "            # terminate\n",
    "            if pbar.n >= args.steps_3:\n",
    "                break\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
